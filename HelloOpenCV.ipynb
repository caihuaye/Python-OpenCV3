{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV 编程入门 - Python 版 - 4.5.1\n",
    "\n",
    "书中很多例子都改编自 [OpenCV 官方文档](https://docs.opencv.org/4.5.1/)，opencv-python 中部分函数与 C++ 版本有些许差别，遇到问题时建议多查阅相关说明和教程：\n",
    "\n",
    "[OpenCV C++ 版本教程](https://docs.opencv.org/4.5.1/d9/df8/tutorial_root.html)\n",
    "\n",
    "[opencv-python 教程](https://docs.opencv.org/4.5.1/d6/d00/tutorial_py_root.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的 OpenCV 版本为 4.5.1\n"
     ]
    }
   ],
   "source": [
    "# 依赖环境 - python 3.8\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 在独立窗口显示动态图（可能的报错原因是未安装依赖包：pip install PyQt5）\n",
    "%matplotlib qt5\n",
    "\"\"\"\n",
    "# 在网页内显示静态图\n",
    "%matplotlib inline\n",
    "# 在独立窗口显示动态图\n",
    "%matplotlib auto\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "# 当前使用的 OpenCV 版本为 4.5.1\n",
    "print(\"当前使用的 OpenCV 版本为\", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分 - 快速上手 OpenCV\n",
    "\n",
    "### 第一章 - 邂逅 OpenCV\n",
    "\n",
    "#### 1.5 - 快速上手 OpenCV 图像处理\n",
    "\n",
    "注意：在像素坐标系中，坐标原点在图像左上角。\n",
    "\n",
    "OpenCV 中的 (x, y) 表示图像矩阵的 列、行。\n",
    "\n",
    "C++ 中 img.size() 返回的 (x, y) 表示图像矩阵的 列、行。\n",
    "\n",
    "Python 中 img.shape 返回的 (x, y, d) 表示图像矩阵的 **行、列**、通道数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像显示\n",
    "img = cv2.imread(\"./image/1_HelloOpenCV.jpg\")   # 载入图像，第二个参数含义：0 灰度图，1 彩色图，2 任意深度图，默认为 1\n",
    "cv2.imshow(\"Showing the image\", img)  # 显示图像\n",
    "cv2.waitKey(0)  # 等待任意按键按下\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像腐蚀\n",
    "img = cv2.imread(\"./image/3_ImageErode.jpg\")\n",
    "element = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "dst = cv2.erode(img, element)\n",
    "result = np.hstack([img, dst])\n",
    "cv2.imshow(\"Eroding the image\", result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像模糊\n",
    "img = cv2.imread(\"./image/4_BlurImage.jpg\")\n",
    "dst = cv2.blur(img, (7, 7))\n",
    "result = np.hstack([img, dst])\n",
    "cv2.imshow(\"Blurring the image\", result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canny 边缘检测\n",
    "img = cv2.imread(\"./image/5_Canny.jpg\")\n",
    "cv2.imshow(\"Original image: \", img)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    # 转为灰度图\n",
    "img_gray_blur = cv2.blur(img_gray, (3, 3))    # 降噪\n",
    "img_edge = cv2.Canny(img_gray_blur, 3, 9, 3)\n",
    "result = np.hstack([img_gray, img_gray_blur, img_edge])\n",
    "cv2.imshow(\"Canny edge detection\", result)\n",
    "\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 - OpenCv 视频操作基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取并播放视频\n",
    "capture = cv2.VideoCapture(\"./video/6_PlayVideo.avi\")\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    if not ret: # 正确读取帧时 ret 为真\n",
    "        print(\"Cannot receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(30) == ord('q'): # 延时 30ms\n",
    "        break   # 若按下 q 则退出视频播放\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用摄像头采集图像\n",
    "capture = cv2.VideoCapture(0)\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_blur = cv2.blur(frame_gray, (7, 7))\n",
    "    frame_edge = cv2.Canny(frame_blur, 3, 9, 3)\n",
    "    cv2.imshow(\"frame\", frame_edge)\n",
    "    if cv2.waitKey(30) == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三章 - HighGUI 图形用户界面初步\n",
    "\n",
    "#### 3.2 - 滑动条的创建和使用 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建滑动条\n",
    "alpha_slider_max = 100  # Alpha 值的最大值\n",
    "alpha_slider_init = 70  # 设置滑动条初值\n",
    "title_window = 'Linear Blend'\n",
    "\n",
    "\n",
    "# def on_trackbar(val):\n",
    "def on_trackbar(_):\n",
    "    val = cv2.getTrackbarPos(trackbar_name, title_window)   # 获取当前轨迹条的位置\n",
    "    alpha = float(val / alpha_slider_max)  # 求出当前 alpha 值相对于最大值的比例\n",
    "    beta = (1.0 - alpha)    # 则 bate 值为 1 减去 alpha 值\n",
    "    dst = cv2.addWeighted(src1, alpha, src2, beta, 0.0) # 根据 alpha 和 beta 值进行线性混合\n",
    "    cv2.imshow(title_window, dst)\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Code for Adding a Trackbar to our applications tutorial.')\n",
    "parser.add_argument(\n",
    "    '--input1', help='Path to the first input image.', default=\"./image/17_1.jpg\")\n",
    "parser.add_argument(\n",
    "    '--input2', help='Path to the second input image.', default=\"./image/17_2.jpg\")\n",
    "args = parser.parse_args(args=[])\n",
    "src1 = cv2.imread(cv2.samples.findFile(args.input1))\n",
    "src2 = cv2.imread(cv2.samples.findFile(args.input2))\n",
    "if src1 is None:\n",
    "    print('Could not open or find the image: ', args.input1)\n",
    "    exit(0)\n",
    "if src2 is None:\n",
    "    print('Could not open or find the image: ', args.input2)\n",
    "    exit(0)\n",
    "\n",
    "cv2.namedWindow(title_window)   # 创建窗体\n",
    "trackbar_name = 'Alpha %d' % alpha_slider_max   # 在创建的窗体中创建一个滑动条控件\n",
    "cv2.createTrackbar(trackbar_name, title_window, alpha_slider_init, alpha_slider_max, on_trackbar)\n",
    "\n",
    "# Show some stuff\n",
    "on_trackbar(0)\n",
    "# Wait until user press some key\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - 鼠标操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt1: x = 171, y = 188\n",
      "pt2: x = 514, y = 384\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n",
    "本文链接：https://blog.csdn.net/bby1987/article/details/107302398\n",
    "\"\"\"\n",
    "WIN_NAME = 'draw_rect'\n",
    "\n",
    "\n",
    "class Rect(object):\n",
    "    def __init__(self):\n",
    "        self.tl = (0, 0)    # top-left point\n",
    "        self.br = (0, 0)    # bottom-right point\n",
    "\n",
    "    def regularize(self):\n",
    "        # When moving from the bottom-right to the top-left, you should make sure tl = TopLeft point, br = BottomRight point\n",
    "        pt1 = (min(self.tl[0], self.br[0]), min(self.tl[1], self.br[1]))\n",
    "        pt2 = (max(self.tl[0], self.br[0]), max(self.tl[1], self.br[1]))\n",
    "        self.tl = pt1\n",
    "        self.br = pt2\n",
    "\n",
    "\n",
    "class DrawRects(object):\n",
    "    def __init__(self, image, color, thickness=1):\n",
    "        self.original_image = image\n",
    "        self.image_for_show = image.copy()\n",
    "        self.color = color\n",
    "        self.thickness = thickness\n",
    "        self.rects = []\n",
    "        self.current_rect = Rect()\n",
    "        self.left_button_down = False\n",
    "\n",
    "    @staticmethod\n",
    "    def __clip(value, low, high):\n",
    "        # clip value between low and high\n",
    "        output = max(value, low)\n",
    "        output = min(output, high)\n",
    "        return output\n",
    "\n",
    "    def shrink_point(self, x, y):\n",
    "        # shrink point (x, y) to inside image_for_show, that is, limit the drawn rectangle to the window\n",
    "        height, width = self.image_for_show.shape[0:2]\n",
    "        x_shrink = self.__clip(x, 0, width)\n",
    "        y_shrink = self.__clip(y, 0, height)\n",
    "        return (x_shrink, y_shrink)\n",
    "\n",
    "    def append(self):\n",
    "        # add a rect to rects list\n",
    "        self.rects.append(copy.deepcopy(self.current_rect))\n",
    "\n",
    "    def pop(self):\n",
    "        # pop a rect from rects list\n",
    "        rect = Rect()\n",
    "        if self.rects:\n",
    "            rect = self.rects.pop()\n",
    "        return rect\n",
    "\n",
    "    def reset_image(self):\n",
    "        # reset image_for_show using original image\n",
    "        self.image_for_show = self.original_image.copy()\n",
    "\n",
    "    def draw(self):\n",
    "        # draw a series of rects on image_for_show\n",
    "        for rect in self.rects:\n",
    "            cv2.rectangle(self.image_for_show, rect.tl, rect.br,\n",
    "                          color=self.color, thickness=self.thickness)\n",
    "\n",
    "    def draw_current_rect(self):\n",
    "        # draw current rect on image_for_show\n",
    "        cv2.rectangle(self.image_for_show,\n",
    "                      self.current_rect.tl, self.current_rect.br,\n",
    "                      color=self.color, thickness=self.thickness)\n",
    "\n",
    "\n",
    "def onmouse_draw_rect(event, x, y, flags, draw_rects):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # pick first point of rect\n",
    "        print('pt1: x = %d, y = %d' % (x, y))\n",
    "        draw_rects.left_button_down = True\n",
    "        draw_rects.current_rect.tl = (x, y)\n",
    "    if draw_rects.left_button_down and event == cv2.EVENT_MOUSEMOVE:\n",
    "        # pick second point of rect and draw current rect\n",
    "        draw_rects.current_rect.br = draw_rects.shrink_point(x, y)\n",
    "        draw_rects.reset_image()\n",
    "        draw_rects.draw()\n",
    "        draw_rects.draw_current_rect()\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        # finish drawing current rect and append it to rects list\n",
    "        draw_rects.left_button_down = False\n",
    "        draw_rects.current_rect.br = draw_rects.shrink_point(x, y)\n",
    "        print('pt2: x = %d, y = %d' % (draw_rects.current_rect.br[0],\n",
    "                                       draw_rects.current_rect.br[1]))\n",
    "        draw_rects.current_rect.regularize()\n",
    "        draw_rects.append()\n",
    "    if (not draw_rects.left_button_down) and event == cv2.EVENT_RBUTTONDOWN:\n",
    "        # pop the last rect in rects list\n",
    "        draw_rects.pop()\n",
    "        draw_rects.reset_image()\n",
    "        draw_rects.draw()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image = np.zeros((600, 800, 3), np.uint8)   # background\n",
    "    draw_rects = DrawRects(image, (0, 255, 0), 2)\n",
    "    cv2.namedWindow(WIN_NAME)\n",
    "    cv2.setMouseCallback(WIN_NAME, onmouse_draw_rect, draw_rects)\n",
    "    while True:\n",
    "        cv2.imshow(WIN_NAME, draw_rects.image_for_show)\n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分 - 初探 core 组件\n",
    "\n",
    "### 第四章 - OpenCV 数据结构与基本绘图\n",
    "\n",
    "#### 4.3 - 基本图形的绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本图形的绘制\n",
    "W = 400\n",
    "\n",
    "\n",
    "def my_ellipse(img, angle):\n",
    "    thickness = 2\n",
    "    line_type = 8\n",
    "    cv2.ellipse(img,\n",
    "               (W // 2, W // 2),    # 椭圆中心点\n",
    "               (W // 4, W // 16),   # 大小位于该矩形框内\n",
    "               angle,               # 椭圆旋转角度\n",
    "               0,                   # 扩展的弧度的变化范围\n",
    "               360,\n",
    "               (255, 0, 0),         # 图形颜色\n",
    "               thickness,           # 线宽 \n",
    "               line_type)           # 线型 - 联通\n",
    "\n",
    "\n",
    "def my_filled_circle(img, center):\n",
    "    thickness = -1\n",
    "    line_type = 8\n",
    "    cv2.circle(img,\n",
    "              center,\n",
    "              W // 32,  # 圆的半径\n",
    "              (0, 0, 255),\n",
    "              thickness,\n",
    "              line_type)\n",
    "\n",
    "# 绘制凹多边形\n",
    "def my_polygon(img):\n",
    "    line_type = 8\n",
    "    # Create some points\n",
    "    ppt = np.array([[W / 4, 7 * W / 8], [3 * W / 4, 7 * W / 8],\n",
    "                    [3 * W / 4, 13 * W / 16], [11 * W / 16, 13 * W / 16],\n",
    "                    [19 * W / 32, 3 * W / 8], [3 * W / 4, 3 * W / 8],\n",
    "                    [3 * W / 4, W / 8], [26 * W / 40, W / 8],\n",
    "                    [26 * W / 40, W / 4], [22 * W / 40, W / 4],\n",
    "                    [22 * W / 40, W / 8], [18 * W / 40, W / 8],\n",
    "                    [18 * W / 40, W / 4], [14 * W / 40, W / 4],\n",
    "                    [14 * W / 40, W / 8], [W / 4, W / 8],\n",
    "                    [W / 4, 3 * W / 8], [13 * W / 32, 3 * W / 8],\n",
    "                    [5 * W / 16, 13 * W / 16], [W / 4, 13 * W / 16]], np.int32)\n",
    "    ppt = ppt.reshape((-1, 1, 2))   # 一行两列，每行对应一个顶点；第三个维度由矩阵确定\n",
    "    cv2.fillPoly(img, [ppt], (255, 255, 255), line_type)\n",
    "    # Only drawind the lines would be:\n",
    "    # cv2.polylines(img, [ppt], True, (255, 0, 255), line_type)   # 第三个参数确定多边形是否闭合\n",
    "\n",
    "\n",
    "def my_line(img, start, end):\n",
    "    thickness = 2\n",
    "    line_type = 8\n",
    "    cv2.line(img,\n",
    "            start,\n",
    "            end,\n",
    "            (0, 0, 0),\n",
    "            thickness,\n",
    "            line_type)\n",
    "\n",
    "\n",
    "atom_window = \"Drawing 1: Atom\"\n",
    "rook_window = \"Drawing 2: Rook\"\n",
    "# Create black empty images\n",
    "size = W, W, 3\n",
    "atom_image = np.zeros(size, dtype=np.uint8)\n",
    "rook_image = np.zeros(size, dtype=np.uint8)\n",
    "# 1.a. Creating ellipses\n",
    "my_ellipse(atom_image, 90)\n",
    "my_ellipse(atom_image, 0)\n",
    "my_ellipse(atom_image, 45)\n",
    "my_ellipse(atom_image, -45)\n",
    "# 1.b. Creating circles\n",
    "my_filled_circle(atom_image, (W // 2, W // 2))\n",
    "# 2. Draw a rook\n",
    "# ------------------\n",
    "# 2.a. Create a convex polygon\n",
    "my_polygon(rook_image)\n",
    "cv2.rectangle(rook_image,\n",
    "             (0, 7 * W // 8),   # 矩形左上角顶点\n",
    "             (W, W),            # 矩形右下角顶点，注意原点在窗口的左上角，(x,y) 对应矩阵的列和行\n",
    "             (0, 255, 255),\n",
    "             -1,\n",
    "             8)\n",
    "#  2.c. Create a few lines\n",
    "my_line(rook_image, (0, 15 * W // 16), (W, 15 * W // 16))\n",
    "my_line(rook_image, (W // 4, 7 * W // 8), (W // 4, W))\n",
    "my_line(rook_image, (W // 2, 7 * W // 8), (W // 2, W))\n",
    "my_line(rook_image, (3 * W // 4, 7 * W // 8), (3 * W // 4, W))\n",
    "cv2.imshow(atom_window, atom_image)\n",
    "cv2.moveWindow(atom_window, 0, 200)\n",
    "cv2.imshow(rook_window, rook_image)\n",
    "cv2.moveWindow(rook_window, W, 200)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第五章 - core 组件进阶\n",
    "\n",
    "#### 5.1 - 访问图像中的像素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 times\n",
      "0.000056 s\n"
     ]
    }
   ],
   "source": [
    "# 计时函数\n",
    "freq = cv2.getTickFrequency()  # 返回 CPU 一秒钟所走的时钟周期数\n",
    "print(\"%d times\" % freq)\n",
    "\n",
    "time = cv2.getTickCount()   # 返回 CPU 自某个事件以来走过的时钟周期数\n",
    "# ...procedure...\n",
    "time = (cv2.getTickCount() - time) / cv2.getTickFrequency() # 程序运行时间\n",
    "print(\"%f s\" % time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 - ROI 区域图像叠加 & 图像混合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初级图像混合 -> ROI(Region of Interest) + addWeighted\n",
    "img = cv2.imread(\"./image/26_dota_jugg.jpg\")\n",
    "logo = cv2.imread(\"./image/26_dota_logo.jpg\")\n",
    "img_roi = img[200:200+logo.shape[0], 550:550+logo.shape[1]] # 切片\n",
    "cv2.addWeighted(img_roi, 0.5, logo, 0.3, 0, img_roi)\n",
    "# img_roi = cv2.addWeighted(img_roi, 0.5, logo, 0.3, 0) # 与上一行的写法等价；当 dst 未指定时，使用该行代码\n",
    "cv2.imshow(\"the example of region linear blend\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 - 分离颜色通道、多通道图像混合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 颜色通道分离 split & 多通道图像混合 merge\n",
    "img = cv2.imread(\"./image/26_dota_jugg.jpg\")\n",
    "blue, green, red = cv2.split(img)\n",
    "zeros = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "cv2.imshow(\"split the image to blue channel\", cv2.merge([blue, zeros, zeros]))\n",
    "\n",
    "# split()、merge() 和 cvtColor() 都是 mixChannels() 的一部分\n",
    "# mixChannels() 的作用是将输入参数的某通道复制给输出参数的特定通道\n",
    "rgba = np.zeros([500, 500, 4], dtype=\"uint8\")\n",
    "for i in range(4):\n",
    "    rgba[:,:,i] = 50 + i*50\n",
    "bgr = np.zeros([rgba.shape[0], rgba.shape[1], 3], dtype=\"uint8\")\n",
    "alpha = np.zeros([rgba.shape[0], rgba.shape[1]], dtype=\"uint8\")\n",
    "\n",
    "# 将一个 4 通道的 RGBA 图像转化为 3 通道的 BGR 和一个单通道的 Alpha 图像\n",
    "from_to = [0,2, 1,1, 2,0, 3,3]\n",
    "cv2.mixChannels(src=[rgba], dst=[bgr, alpha], fromTo=from_to)\n",
    "cv2.imshow(\"rgba\", rgba)\n",
    "cv2.imshow(\"bgr\", bgr)\n",
    "cv2.imshow(\"alpha\", alpha)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 - 图像对比度、亮度值调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像对比度和亮度值调整\n",
    "def on_contrast_and_bright(_):\n",
    "    contrast = cv2.getTrackbarPos(\"Contrast\", \"result\")\n",
    "    bright = cv2.getTrackbarPos(\"Bright\", \"result\")\n",
    "    \n",
    "    mat_contrast = np.ones(img.shape, dtype=img.dtype) * contrast * 0.01\n",
    "    mat_bright = np.ones(img.shape, dtype=img.dtype) * bright\n",
    "    \"\"\"\n",
    "    cv2.add/multiply 与 saturate_cast 模板函数类似，用于溢出保护\n",
    "    cv2.add/multiply 中两个矩阵的尺寸应相同，且数据类型不一致时，需要声明返回图像的数据类型\n",
    "    cv2 的 dtype 与 numpy 不同，必须使用标识符（或对应的整数）    \n",
    "    \"\"\"\n",
    "    dst = cv2.add(\n",
    "        cv2.multiply(mat_contrast, img, dtype=cv2.CV_8UC3),\n",
    "        mat_bright)\n",
    "    \n",
    "    result = np.hstack([img, dst])\n",
    "    cv2.imshow(\"result\", result)\n",
    "\n",
    "img = cv2.imread(\"./image/27_ChangeContrastAndBright.jpg\")\n",
    "contrast_init = 80\n",
    "bright_init = 80\n",
    "\n",
    "cv2.namedWindow(\"result\")\n",
    "cv2.createTrackbar(\"Contrast\", \"result\", contrast_init,\n",
    "                   300, on_contrast_and_bright)\n",
    "cv2.createTrackbar(\"Bright\", \"result\", bright_init,\n",
    "                   200, on_contrast_and_bright)\n",
    "\n",
    "on_contrast_and_bright(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 - 离散傅里叶变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 离散傅里叶变换 & 逆变换\n",
    "img = cv2.imread('./image/28_DFT.jpg', 0)   # DFT 要求单通道或双通道图像\n",
    "\n",
    "# Performance Optimization of DFT\n",
    "rows, cols = img.shape\n",
    "nrows = cv2.getOptimalDFTSize(rows)\n",
    "ncols = cv2.getOptimalDFTSize(cols)\n",
    "right = ncols - cols\n",
    "bottom = nrows - rows\n",
    "bordertype = cv2.BORDER_CONSTANT  # just to avoid line breakup in PDF file\n",
    "nimg = cv2.copyMakeBorder(img, 0, bottom, 0, right, bordertype, value=0)\n",
    "\n",
    "dft = cv2.dft(np.float32(nimg), flags=cv2.DFT_COMPLEX_OUTPUT)    # 就地操作(in-place)；频域值范围远大于空间值，需要储存在 float 格式中；分为实部和虚部\n",
    "dft_shift = np.fft.fftshift(dft)  # 将原点平移到中心\n",
    "magnitude_spectrum = 20 * np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))  # 频谱图；首先将复数转换为幅值，再取对数进行尺度缩小\n",
    "\n",
    "crow, ccol = rows//2, cols//2\n",
    "# create a mask first, center square is 1, remaining all zeros\n",
    "mask = np.zeros((nrows, ncols, 2), np.uint8)\n",
    "mask[crow-30:crow+30, ccol-30:ccol+30] = 1\n",
    "# apply mask and inverse DFT\n",
    "fshift = dft_shift * mask\n",
    "f_ishift = np.fft.ifftshift(fshift)\n",
    "img_back = cv2.idft(f_ishift)\n",
    "img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n",
    "\n",
    "plt.subplot(131), plt.imshow(img, cmap='gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132), plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133), plt.imshow(img_back, cmap='gray')\n",
    "plt.title('Inverse DFT'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三部分 - 掌握 imgproc 组件\n",
    "\n",
    "### 第六章 - 图像处理\n",
    "\n",
    "#### 6.1 & 6.2 - 线性和非线性滤波"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the size of mean blur is 10, PSNR = 19.586833\n"
     ]
    }
   ],
   "source": [
    "# 图像处理\n",
    "img = cv2.imread(\"./image/34_LinearImageFilter.jpg\")\n",
    "img_bf = cv2.imread(\"./image/36_BilateralFilter.png\")\n",
    "\n",
    "\n",
    "def on_box_filter(_):\n",
    "    size_box_filter = cv2.getTrackbarPos(\"Box Filter\", \"Box Filter Result\")\n",
    "    \n",
    "    # 方框滤波\n",
    "    filter = cv2.boxFilter(img, ddepth=2, ksize=(size_box_filter+1, size_box_filter+1), anchor=(-1, -1), normalize=False) # ddepth 指定输出图像的深度，-1 代表原图深度；anchor 默认值为 (-1, -1)，即核的中心\n",
    "    \n",
    "    result = np.hstack([img, filter])\n",
    "    cv2.imshow(\"Box Filter Result\", result)\n",
    "    \n",
    "    \n",
    "def on_mean_blur(_):\n",
    "    size_mean_blur = cv2.getTrackbarPos(\"Mean Blur\", \"Mean Blur Result\")\n",
    "    \n",
    "    # 均值滤波 - 均一化后的方框滤波\n",
    "    filter = cv2.blur(img, ksize=(size_mean_blur+1, size_mean_blur+1), anchor=(-1, -1))\n",
    "    # filter = cv2.boxFilter(img, ddepth=-1, ksize=(size_mean_blur+1, size_mean_blur+1), anchor=(-1, -1), normalize=True)\n",
    "    \n",
    "    psnr = cv2.PSNR(img, filter, R=255)\n",
    "    print(\"When the size of mean blur is %d, PSNR = %f\" % (size_mean_blur, psnr))\n",
    "    \n",
    "    result = np.hstack([img, filter])\n",
    "    cv2.imshow(\"Mean Blur Result\", result)\n",
    "    \n",
    "    \n",
    "def on_gaussian_blur(_):\n",
    "    size_gaussian_blur = cv2.getTrackbarPos(\"Gaussian Blur\", \"Gaussian Blur Result\")\n",
    "    \n",
    "    # 高斯滤波 - 毛玻璃特效 - ksize 必须为零或正奇数\n",
    "    filter = cv2.GaussianBlur(img, ksize=(size_gaussian_blur*2+1, size_gaussian_blur*2+1), sigmaX=0, sigmaY=0)\n",
    "\n",
    "    result = np.hstack([img, filter])\n",
    "    cv2.imshow(\"Gaussian Blur Result\", result)\n",
    "    \n",
    "\n",
    "def on_median_blur(_):\n",
    "    size_median_blur = cv2.getTrackbarPos(\"Median Blur\", \"Median Blur Result\")\n",
    "    \n",
    "    # 中值滤波 - 保留边缘信息 - runtime 是均值滤波的 5 倍以上\n",
    "    filter = cv2.medianBlur(img, ksize=size_median_blur*2+3)  # ksize 必须是大于 1 的奇数\n",
    "    \n",
    "    result = np.hstack([img, filter])\n",
    "    cv2.imshow(\"Median Blur Result\", result)\n",
    "\n",
    "\n",
    "def on_bilateral_filter(_):\n",
    "    size_bf = cv2.getTrackbarPos(\"Bilateral Filter\", \"Bilateral Filter Result\")\n",
    "    \n",
    "    # 双边滤波 - 磨皮效果\n",
    "    \"\"\"\n",
    "    d 表示在过滤过程中每个像素领域的直径；当 d > 0 时，d 指定了领域大小且于 sigmaSpace 无关，否则 d 正比于 sigmaSpace\n",
    "    sigmaColor 参数值越大，表明该像素领域内有越宽广的的颜色会被混合在一起，产生较大的半相等颜色区域\n",
    "    sigmaSpace 参数值越大，意味着越远的像素会相互影响，从而使更大的区域中足够相似的颜色获取相同的颜色\n",
    "    \"\"\"\n",
    "    filter = cv2.bilateralFilter(img_bf, d=size_bf, sigmaColor=size_bf*2, sigmaSpace=size_bf/2)\n",
    "    \n",
    "    result = np.hstack([img_bf, filter])\n",
    "    cv2.imshow(\"Bilateral Filter Result\", result)\n",
    "\n",
    "\n",
    "# === 线性滤波 ===\n",
    "# 方框滤波\n",
    "cv2.namedWindow(\"Box Filter Result\")\n",
    "cv2.createTrackbar(\"Box Filter\", \"Box Filter Result\", 6, 50, on_box_filter)\n",
    "on_box_filter(0)\n",
    "# 均值滤波 - 均一化后的方框滤波\n",
    "cv2.namedWindow(\"Mean Blur Result\")\n",
    "cv2.createTrackbar(\"Mean Blur\", \"Mean Blur Result\", 10, 50, on_mean_blur)\n",
    "on_mean_blur(0)\n",
    "# 高斯滤波 - 毛玻璃特效 - ksize 必须为零或正奇数\n",
    "cv2.namedWindow(\"Gaussian Blur Result\")\n",
    "cv2.createTrackbar(\"Gaussian Blur\", \"Gaussian Blur Result\", 6, 50, on_gaussian_blur)\n",
    "on_gaussian_blur(0)\n",
    "\n",
    "# === 非线性滤波 ===\n",
    "# 中值滤波 - 保留边缘信息 - runtime 是均值滤波的 5 倍以上\n",
    "cv2.namedWindow(\"Median Blur Result\")\n",
    "cv2.createTrackbar(\"Median Blur\", \"Median Blur Result\", 10, 50, on_median_blur)\n",
    "on_median_blur(0)\n",
    "# 双边滤波 - 磨皮效果\n",
    "cv2.namedWindow(\"Bilateral Filter Result\")\n",
    "cv2.createTrackbar(\"Bilateral Filter\", \"Bilateral Filter Result\", 25, 50, on_bilateral_filter)\n",
    "on_bilateral_filter(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 & 6.4 - 形态学滤波"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 形态学滤波 === 形态学操作就是基于形状的一系列图像处理操作\n",
    "# img = cv2.imread(\"./image/3_ImageErode.jpg\")\n",
    "img = cv2.imread(\"./image/48_Morphology.jpg\")\n",
    "\n",
    "\n",
    "def Open(img, element, iter):\n",
    "    return cv2.dilate(cv2.erode(img, kernel=element, iterations=iter), kernel=element, iterations=iter)\n",
    "\n",
    "\n",
    "def Close(img, element, iter):\n",
    "    return cv2.erode(cv2.dilate(img, kernel=element, iterations=iter), kernel=element, iterations=iter)\n",
    "\n",
    "\n",
    "def on_morphology(_):\n",
    "    func = cv2.getTrackbarPos(\"Function\", \"Morphology Result\")\n",
    "    size = cv2.getTrackbarPos(\"Element Size\", \"Morphology Result\")\n",
    "    iter = cv2.getTrackbarPos(\"Iteration\", \"Morphology Result\")\n",
    "    shape = cv2.getTrackbarPos(\"Shape\", \"Morphology Result\")\n",
    "    \n",
    "    \"\"\"\n",
    "    返回值为指定形状和尺寸的结构元素（内核矩阵）\n",
    "    可选形状为矩形 MORPH_RECT 、交叉形 MORPH_CROSS 、椭圆形 MORPH_ELLIPSE\n",
    "    交叉形的 element 形状唯一依赖于锚点的位置，而其他情况下，锚点只影响形态学运算结果的偏移\n",
    "    \"\"\"\n",
    "    if shape == 0:\n",
    "        element = cv2.getStructuringElement(\n",
    "            shape=cv2.MORPH_RECT, ksize=(size+1, size+1), anchor=(-1, -1))\n",
    "    elif shape == 1:\n",
    "        element = cv2.getStructuringElement(\n",
    "            shape=cv2.MORPH_CROSS, ksize=(size+1, size+1), anchor=(size, size))\n",
    "    else:\n",
    "        element = cv2.getStructuringElement(\n",
    "            shape=cv2.MORPH_ELLIPSE, ksize=(size+1, size+1), anchor=(-1, -1))\n",
    "    \n",
    "    # 进行腐蚀或膨胀操作\n",
    "    if func == 0:\n",
    "        # 图像腐蚀 - 求局部最小值\n",
    "        dst = cv2.erode(img, element, iterations=iter) # iteration 表示迭代使用函数的次数，其值越高，模糊程度(腐蚀程度)就越高 呈正相关关系且只能是整数，默认值为 1\n",
    "    elif func == 1:\n",
    "        # 图像膨胀 - 求局部最大值\n",
    "        dst = cv2.dilate(img, element, iterations=iter)\n",
    "    elif func == 2:\n",
    "        # 开运算 - 先腐蚀后膨胀\n",
    "        \"\"\"\n",
    "        可以用来消除小物体，在纤细点处分离物体\n",
    "        并且在平滑较大物体的边界的同时不明显改变其面积\n",
    "        其结果是放大了裂缝或者局部低亮度区域\n",
    "        \"\"\"\n",
    "        # dst = Open(img, element, iter)\n",
    "        dst = cv2.morphologyEx(img, cv2.MORPH_OPEN, element, iterations=iter)\n",
    "    elif func == 3:\n",
    "        # 闭运算 - 先膨胀后腐蚀 - 能够排除小型黑洞\n",
    "        # dst = Close(img, element, iter)\n",
    "        dst = cv2.morphologyEx(img, cv2.MORPH_CLOSE, element, iterations=iter)\n",
    "    elif func == 4:\n",
    "        # 形态学梯度 - 膨胀图与腐蚀图之差 - 可以 突出/保留 物体的边缘轮廓\n",
    "        # dst = cv2.dilate(img, element, iterations=iter) - cv2.erode(img, element, iterations=iter)\n",
    "        dst = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, element, iterations=iter)\n",
    "    elif func == 5:\n",
    "        # 顶帽(Top Hat)运算 - 原图像与开运算之差\n",
    "        \"\"\"\n",
    "        用来分离比临近点亮一些的斑块，突出比原图轮廓周围更明亮的区域\n",
    "        在一幅图像具有大幅的背景，而微小物品比较有规律的情况下，可以使用顶帽运算进行背景提取\n",
    "        \"\"\"\n",
    "        # dst = img - Open(img, element, iter)\n",
    "        dst = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, element, iterations=iter)\n",
    "    elif func == 6:\n",
    "        # 黑帽(Black Hat)运算 - 闭运算与原图像之差 - 用来分离比临近点暗一些的斑块，突出比原图轮廓周围更暗的区域\n",
    "        # dst = Close(img, element, iter) - img\n",
    "        dst = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, element, iterations=iter)\n",
    "\n",
    "    result = np.hstack([img, dst])  # 水平排列(按列排列)的堆栈数组，注意保持维度(图像通道数)一致\n",
    "    cv2.imshow(\"Morphology Result\", result)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Morphology Result\")\n",
    "cv2.createTrackbar(\"Function\", \"Morphology Result\", 0, 6, on_morphology)\n",
    "cv2.createTrackbar(\"Element Size\", \"Morphology Result\", 1, 50, on_morphology)\n",
    "cv2.createTrackbar(\"Iteration\", \"Morphology Result\", 1, 50, on_morphology)\n",
    "cv2.createTrackbar(\"Shape\", \"Morphology Result\", 0, 2, on_morphology)\n",
    "on_morphology(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 - 漫水填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3127 pixels had been repainted.\n",
      "there are 575 pixels had been repainted.\n",
      "there are 2027 pixels had been repainted.\n",
      "there are 1257 pixels had been repainted.\n",
      "Restore the original image\n",
      "there are 3674 pixels had been repainted.\n",
      "there are 1631 pixels had been repainted.\n",
      "there are 4782 pixels had been repainted.\n",
      "the program has exited\n"
     ]
    }
   ],
   "source": [
    "# 漫水填充 - PS 魔术棒功能\n",
    "img = cv2.imread(\"./image/50_floodFill2.jpg\")\n",
    "mask = np.zeros([img.shape[0]+2, img.shape[1]+2], dtype=img.dtype)  # 掩膜比需填充的图像大一圈\n",
    "\n",
    "fill_mode = 1       # 漫水填充模式\n",
    "connectivity = 4    # 表示 floodFill 函数标识符低八位的连通域值\n",
    "new_mask_val = 255  # 新的重新绘制的像素值\n",
    "\n",
    "\n",
    "def on_mouse(event: int, x: int, y: int, *_):\n",
    "    if event is not cv2.EVENT_LBUTTONDOWN:  # 判断鼠标左键是否被按下\n",
    "        return\n",
    "\n",
    "    loDiff = cv2.getTrackbarPos(\"loDiff\", \"Result\")\n",
    "    upDiff = cv2.getTrackbarPos(\"upDiff\", \"Result\")\n",
    "    fill_mode = cv2.getTrackbarPos(\"fill_mode\", \"Result\")\n",
    "    flag_cnt = cv2.getTrackbarPos(\"connectivity\", \"Result\")\n",
    "    \n",
    "    # 空范围的漫水填充，此值设为 0\n",
    "    if fill_mode == 0:\n",
    "        loDiff = 0\n",
    "        upDiff = 0\n",
    "        \n",
    "    \"\"\"\n",
    "    标识符的低八位 (0~7) 为 connectivity，用于控制算法的连通性 - 4连通 或 8连通\n",
    "    中间八位 (8~15) 用于指定填充掩码图像的值\n",
    "    高八位 (16~23) 为 FLOODFILL_FIXED_RANGE 或者 0；设置为前者时，考虑当前像素与种子像素之间的差，否则就考虑当前像素与其相邻像素的差\n",
    "    \"\"\"\n",
    "    connectivity = 8 if flag_cnt == 1 else 4\n",
    "    flags = connectivity + (255 << 8) + (cv2.FLOODFILL_FIXED_RANGE if fill_mode == 1 else 0)\n",
    "    \n",
    "    # 随机生成 BGR 值\n",
    "    blue = np.random.randint(255)\n",
    "    green = np.random.randint(255)\n",
    "    red = np.random.randint(255)\n",
    "    new_val = (blue, green, red)\n",
    "    \n",
    "    area = cv2.floodFill(img, mask,  # img 既是输入，也是输出；mask 比需填充的 img 大一圈\n",
    "        seedPoint=(x, y),  # 种子像素\n",
    "        newVal=new_val,    # 重新绘制的像素值\n",
    "        loDiff=(loDiff, loDiff, loDiff),   # 表示当前观察像素值 与其邻域像素值或待加入的种子像素之间的 亮度或颜色的 负差最大值\n",
    "        upDiff=(upDiff, upDiff, upDiff),   # 同上，为正差最大值\n",
    "        flags=flags)    # int 类型的操作标识符\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"Result\", img)\n",
    "    print(\"there are %d pixels had been repainted.\" % area[0])\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Result\")   # flags 默认为 cv2.WINDOW_AUTOSIZE，即窗口使用原图大小，且不可改变\n",
    "cv2.namedWindow(\"mask\", flags=cv2.WINDOW_NORMAL)  # 表明窗口可以被随意拖动而改变大小\n",
    "\n",
    "# Maximal lower brightness/color difference 负差最大值\n",
    "cv2.createTrackbar(\"loDiff\", \"Result\", 20, 255, lambda x: x)    # 不需要 on_change 时可以随意调用一个无意义函数\n",
    "# Maximal upper brightness/color difference 正差最大值\n",
    "cv2.createTrackbar(\"upDiff\", \"Result\", 20, 255, lambda x: x)\n",
    "cv2.createTrackbar(\"fill_mode\", \"Result\", 1, 2, lambda x: x)\n",
    "cv2.createTrackbar(\"connectivity\", \"Result\", 0, 1, lambda x: x) # 0 -> 4 连通，1 -> 8 连通\n",
    "\n",
    "cv2.setMouseCallback(\"Result\", on_mouse, 0)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"Result\", img)\n",
    "    \n",
    "    key = chr(cv2.waitKey())\n",
    "    \n",
    "    if key == 'q':\n",
    "        print(\"the program has exited\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "    if key == 'r':\n",
    "        print(\"Restore the original image\")\n",
    "        img = cv2.imread(\"./image/50_floodFill2.jpg\")\n",
    "        mask *= 0\n",
    "        cv2.imshow(\"mask\", mask)\n",
    "        cv2.imshow(\"Result\", img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6 - 图像金字塔与图片尺寸缩放\n",
    "\n",
    "=== 图像金字塔 pyrUp() pyrDown() ===\n",
    "\n",
    "高斯金字塔 - 普通的上下采样 - 常应用于图像分割，先低分辨率快速初始分割，再逐层提高分辨率优化\n",
    "\n",
    "拉普拉斯金字塔 - 原图像减去先缩小后放大的图像 - 可以减少信息丢失\n",
    "\n",
    "![img](image_host/2022-01-13-19-54-57.png)\n",
    "\n",
    "其公式如下：\n",
    "\n",
    "$$ L_{i} = G_{i} - Up(G_{i+1}) \\otimes kernel $$\n",
    "\n",
    "其中 $G_{i}$ 表示第 $i$ 层的高斯金字塔图像\n",
    "\n",
    "pyrUp() pyrDown() 与 resize() 功能类似，但不能选择插值方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 图片尺寸缩放 resize() ===\n",
    "\"\"\"\n",
    "interpolation 用于指定插值方式，可选的有：\n",
    "- INTER_NEAREST     最近邻插值\n",
    "- INTER_LINEAR      线性插值（默认值）- 推荐用于放大图像，速度较快\n",
    "- INTER_AREA        区域插值 - 利用像素区域关系的重采样插值 - 推荐用于缩小图像\n",
    "- INTER_CUBIC       三次样条插值 - 超过 4X4 像素邻域内的双三次插值 - 可用于放大图像，但速度较慢\n",
    "- INTER_LANCZOS4    Lanczos 插值 - 超过 8X8 像素邻域的 Lanczos 插值\n",
    "\"\"\"\n",
    "img = cv2.imread(\"./image/54_PyrAndResize.jpg\")\n",
    "dst_shrink = cv2.resize(img, (img.shape[0]//2, img.shape[1]//2), interpolation=cv2.INTER_AREA)\n",
    "dst_enlarge = cv2.resize(img, (img.shape[0]*2, img.shape[1]*2), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "cv2.imshow(\"Original image\", img)\n",
    "cv2.imshow(\"Shrink image\", dst_shrink)\n",
    "cv2.imshow(\"Enlarge image\", dst_enlarge)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the linear interpolation takes 0.000140 s\n",
      "the cubic interpolation takes 0.030029 s\n"
     ]
    }
   ],
   "source": [
    "# resize() 对比不同插值方式\n",
    "img = cv2.imread(\"./image/54_PyrAndResize.jpg\")\n",
    "\n",
    "modes = [cv2.INTER_LINEAR, cv2.INTER_CUBIC]\n",
    "names = [\"linear\", \"cubic\"]\n",
    "times = 5   # 连续缩放次数\n",
    "\n",
    "for index, mode in enumerate(modes):\n",
    "    for _ in range(times):  # 先用 区域插值 连续缩小 5 次\n",
    "        img = cv2.resize(img, (img.shape[0]//2, img.shape[1]//2), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    time = cv2.getTickCount()\n",
    "    for _ in range(times):  # 再分别用 线性插值和三次样条插值 连续放大 5 次\n",
    "        img = cv2.resize(img, (img.shape[0]*2, img.shape[1]*2), interpolation=mode)\n",
    "    time = (cv2.getTickCount() - time) / cv2.getTickFrequency()\n",
    "    print(\"the %s interpolation takes %f s\" % (names[index], time))\n",
    "\n",
    "    if mode == cv2.INTER_LINEAR:    # 分别记录结果\n",
    "        dst_linear = img\n",
    "    else:\n",
    "        dst_cubic = img\n",
    "\n",
    "    img = cv2.imread(\"./image/54_PyrAndResize.jpg\") # 重置回原图\n",
    "\n",
    "\"\"\"\n",
    "Terminal output is as follows:\n",
    "    the linear interpolation takes 0.000135 s\n",
    "    the cubic interpolation takes 0.000326 s\n",
    "    \n",
    "可见，三次样条插值不仅效率低于线性插值，\n",
    "多次缩放后的结果还会出现网格化，\n",
    "而线性插值却有雾化的朦胧美\n",
    "\"\"\"\n",
    "result = np.hstack([img, dst_linear, dst_cubic])\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7 - 阈值化\n",
    "\n",
    "![img](image_host/2022-01-13-19-57-56.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本阈值操作\n",
    "## 固定阈值操作 Threshold() - 像素级分割\n",
    "\"\"\"\n",
    "THRESH_BINARY       二进制阈值 - 二值阈值化\n",
    "THRESH_BINARY_INV   反二进制阈值 - 反向二值阈值化并反转\n",
    "THRESH_TRUNC        截断阈值 - 截断阈值化\n",
    "THRESH_TOZERO       反阈值化为 0 - 超过阈值被置为 0\n",
    "THRESH_TOZERO_INV   阈值化为 0 - 低于阈值被置为 0\n",
    "\"\"\"\n",
    "## 自适应阈值操作 adaptiveThreshold() - patch级阈值化\n",
    "\n",
    "img = cv2.imread(\"./image/55_threshold.jpg\")\n",
    "modes = [cv2.THRESH_BINARY, cv2.THRESH_BINARY_INV,\n",
    "         cv2.THRESH_TRUNC, cv2.THRESH_TOZERO, cv2.THRESH_TOZERO_INV]\n",
    "\n",
    "\n",
    "def on_threshold(_):\n",
    "    index = cv2.getTrackbarPos(\"Mode\", \"Result\")\n",
    "    thresh = cv2.getTrackbarPos(\"Threshold\", \"Result\")\n",
    "\n",
    "    # 返回 double 类型的阈值和处理后的图像\n",
    "    thre, dst = cv2.threshold(img, thresh, maxval=255, type=modes[index])\n",
    "    cv2.imshow(\"Result\", dst)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Result\", cv2.WINDOW_NORMAL)\n",
    "cv2.createTrackbar(\"Mode\", \"Result\", 0, len(modes)-1, on_threshold)\n",
    "cv2.createTrackbar(\"Threshold\", \"Result\", 0, 255, on_threshold)\n",
    "on_threshold(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第七章 - 图像变换\n",
    "\n",
    "#### 7.1 - 边缘检测\n",
    "\n",
    "##### 7.1.2 - Canny 算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny 算子\n",
    "img = cv2.imread(\"./image/56_canny.jpg\")\n",
    "WIN_NAME = \"Canny edge detection\"\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    # 转为灰度图\n",
    "\n",
    "\"\"\"\n",
    "主要评价标准：低错误率、高定位性、最小响应\n",
    "步骤：\n",
    "- 消除噪声 - 高斯平滑滤波器\n",
    "- 计算梯度幅值和方向 - Sobel 滤波器\n",
    "- 非极大值抑制 - 排除 非边缘像素，仅仅保留了一些细线条（候选边缘）\n",
    "- 滞后阈值\n",
    "    滞后阈值需要 高阈值 和 低阈值：\n",
    "    若某一像素位置的幅值 > 高阈值，该像素被保留为边缘像素\n",
    "    若某一像素位置的幅值 < 低阈值，该像素被排除\n",
    "    若低阈值 < 某一像素位置的幅值 < 高阈值，该像素仅仅在连接到一个高于高阈值的像素时被保留\n",
    "\"\"\"\n",
    "img_gray_blur = cv2.blur(img_gray, (3, 3))  # 降噪\n",
    "\n",
    "\n",
    "def on_canny(_):\n",
    "    thre = cv2.getTrackbarPos(\"thre\", WIN_NAME)\n",
    "    aper = cv2.getTrackbarPos(\"aper\", WIN_NAME)\n",
    "    is_l2 = False if cv2.getTrackbarPos(\"is_l2\", WIN_NAME) == 0 else True\n",
    "    \n",
    "    \"\"\"\n",
    "    edges           输出的边缘图。需要和原图有相同的尺寸和类型\n",
    "\n",
    "    threshold1 \n",
    "    threshold2      滞后性阈值，选择两者中的较小值用于边缘连接，\n",
    "                    而较大的值用来控制强边缘的初始段，\n",
    "                    推荐的高低阈值比在 2:1 到 3:1 之间\n",
    "    apertureSize    表示应用 Sobel 算子的孔径大小，\n",
    "                    默认值为 3，必须取 3 5 7\n",
    "    L2gradient      计算图像梯度幅值的标识，默认值为 False\n",
    "    \"\"\"\n",
    "    img_edge = cv2.Canny(img_gray_blur, threshold1=thre, threshold2=thre*3, apertureSize=aper*2+3, L2gradient=is_l2)\n",
    "    \n",
    "    cv2.imshow(WIN_NAME, cv2.copyTo(src=img, mask=img_edge))\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"thre\", WIN_NAME, 3, 50, on_canny)\n",
    "cv2.createTrackbar(\"aper\", WIN_NAME, 0, 2, on_canny)\n",
    "cv2.createTrackbar(\"is_l2\", WIN_NAME, 0, 1, on_canny)\n",
    "on_canny(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.3 - Sobel 算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel 算子\n",
    "\"\"\"\n",
    "离散微分算子 - 结合了高斯平滑和微分求导，因此结果更具抗噪性\n",
    "用来计算图像灰度函数的近似梯度，在图像的任何一点使用此算子，都将会产生对应的梯度矢量或其法矢量\n",
    "\"\"\"\n",
    "img = cv2.imread(\"./image/57_sobel.jpg\")\n",
    "WIN_NAME = \"Sobel Operator\"\n",
    "\n",
    "\n",
    "def on_sobel(_):\n",
    "    # dx >= 0 && dy >= 0 && dx+dy > 0 in function\n",
    "    vdx = cv2.getTrackbarPos(\"value of dx\", WIN_NAME)   # x 方向上的差分阶数\n",
    "    vdy = cv2.getTrackbarPos(\"value of dy\", WIN_NAME)   # y 方向上的差分阶数\n",
    "    mode = cv2.getTrackbarPos(\"mode\", WIN_NAME) # 0 -> 整体方向；1 -> X 方向梯度；2 -> Y 方向梯度S\n",
    "    ksize = cv2.getTrackbarPos(\"ksize\", WIN_NAME) * 2 + 1  # Sobel 核的大小，必须取 1 3 5 7，且 ksize > order\n",
    "    scale = cv2.getTrackbarPos(\"scale\", WIN_NAME) * 0.1   # 计算导数值时可选的缩放因子，默认为 1\n",
    "    delta = cv2.getTrackbarPos(\"delta\", WIN_NAME) * 0.1   # 表示在结果存储到 dst 之前添加到结果的可选增量值，默认为 0\n",
    "    \n",
    "    vdx = vdx if mode != 2 else 0\n",
    "    vdx = vdx if vdx < ksize else (ksize - 1)\n",
    "    vdy = vdy if mode != 1 else 0\n",
    "    vdy = vdy if vdy < ksize else (ksize - 1)\n",
    "    if vdx == 0 and vdy == 0:\n",
    "        vdx = 1\n",
    "    \"\"\"\n",
    "    ddepth 输出图像的深度\n",
    "    - 若 src.depth() = CV_8U，          取 ddepth = -1/CV_16S/CV_32F/CV_64F\n",
    "    - 若 src.depth() = CV_16U/CV_16S，  取 ddepth = -1/CV_32F/CV_64F\n",
    "    - 若 src.depth() = CV_32F，         取 ddepth = -1/CV_32F/CV_64F\n",
    "    - 若 src.depth() = CV_64F，         取 ddepth = -1/CV_64F\n",
    "    \"\"\"\n",
    "    img_sobel = cv2.Sobel(img, ddepth=int(-1/cv2.CV_16S), dx=vdx, dy=vdy, ksize=ksize, scale=scale, delta=delta)\n",
    "    img_sobel_abs = cv2.convertScaleAbs(img_sobel)\n",
    "    cv2.imshow(WIN_NAME, img_sobel_abs)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME, 0)\n",
    "cv2.createTrackbar(\"value of dx\", WIN_NAME, 1, 50, on_sobel)\n",
    "cv2.createTrackbar(\"value of dy\", WIN_NAME, 1, 50, on_sobel)\n",
    "cv2.createTrackbar(\"mode\", WIN_NAME, 0, 2, on_sobel)\n",
    "cv2.createTrackbar(\"ksize\", WIN_NAME, 0, 2, on_sobel)\n",
    "cv2.createTrackbar(\"scale\", WIN_NAME, 10, 100, on_sobel)\n",
    "cv2.createTrackbar(\"delta\", WIN_NAME, 10, 100, on_sobel)\n",
    "on_sobel(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.5 - scharr 滤波器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scharr 滤波器\n",
    "\"\"\"\n",
    "计算图像差分\n",
    "当内核大小为 3 时，由于 Sobel 算子只是求取了导数的近似值，其内核可能产生比较明显的误差。\n",
    "为解决这一问题，OpenCV 提供了 Scharr 函数，仅作用于大小为 3 的内核。\n",
    "Scharr 函数与 Sobel 函数一样快，但结果更加精确。\n",
    "除了没有 ksize 之外，其他参数变量基本一致\n",
    "\"\"\"\n",
    "img = cv2.imread(\"./image/59_Scharr.jpg\")\n",
    "WIN_NAME = \"Scharr Filter\"\n",
    "\n",
    "\n",
    "def on_scharr(_):\n",
    "    # dx >= 0 && dy >= 0 && dx+dy == 1 in function\n",
    "    vdx = cv2.getTrackbarPos(\"value of dx\", WIN_NAME)\n",
    "    scale = cv2.getTrackbarPos(\"scale\", WIN_NAME) * 0.1\n",
    "    delta = cv2.getTrackbarPos(\"delta\", WIN_NAME) * 0.1\n",
    "    \n",
    "    sobel = cv2.Sobel(img, ddepth=int(-1/cv2.CV_16S),\n",
    "        dx=vdx, dy=1-vdx, ksize=3, scale=scale, delta=delta)\n",
    "    sobel = cv2.convertScaleAbs(sobel)\n",
    "    scharr = cv2.Scharr(img, ddepth=int(-1/cv2.CV_16S),\n",
    "        dx=vdx, dy=1-vdx, scale=scale, delta=delta)\n",
    "    scharr = cv2.convertScaleAbs(scharr)\n",
    "    result = np.hstack([sobel, scharr])\n",
    "    cv2.imshow(WIN_NAME, result)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"value of dx\", WIN_NAME, 1, 1, on_scharr)\n",
    "cv2.createTrackbar(\"scale\", WIN_NAME, 10, 100, on_scharr)\n",
    "cv2.createTrackbar(\"delta\", WIN_NAME, 10, 100, on_scharr)\n",
    "on_scharr(0)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.4 - Laplacian 算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian 算子\n",
    "\"\"\"\n",
    "Laplacian 算子是 n 维欧几里得空间中的一个二阶微分算子，定义为梯度 grad 的散度 div。\n",
    "二阶导数可以用来进行检测边缘。\n",
    "因为图像是“二维”，需要在两个方向进行求导，使用 Laplacian 算子将会使求导过程变得简单。\n",
    "由于使用了图像梯度，所以其内部代码调用了 Sobel 算子。\n",
    "\"\"\"\n",
    "img = cv2.imread(\"./image/58_Laplacian.jpg\")\n",
    "WIN_NAME = \"Laplacian Operator\"\n",
    "\n",
    "\n",
    "def on_laplacian(_):\n",
    "    size = cv2.getTrackbarPos(\"size\", WIN_NAME) # 高斯模糊核大小\n",
    "    ksize = cv2.getTrackbarPos(\"ksize\", WIN_NAME) * 2 + 1   # 计算二阶导数的滤波器孔径大小，必须为正奇数，默认值为 1\n",
    "    scale = cv2.getTrackbarPos(\"scale\", WIN_NAME) * 0.1   # 计算拉普拉斯值的时候可选的比例因子，默认值为 1\n",
    "    delta = cv2.getTrackbarPos(\"delta\", WIN_NAME) * 0.1   # 表示在结果存储到目标图之前添加到结果的可选增量值，默认为 0\n",
    "    \n",
    "    # 使用高斯滤波消除噪声\n",
    "    filter = cv2.GaussianBlur(img, ksize=(size*2+1, size*2+1), sigmaX=0, sigmaY=0)\n",
    "    img_gray = cv2.cvtColor(filter, cv2.COLOR_RGB2GRAY) # 转换为灰度图\n",
    "    img_laplacian = cv2.Laplacian(img_gray, ddepth=cv2.CV_16S, ksize=ksize, scale=scale, delta=delta)\n",
    "    img_abs = cv2.convertScaleAbs(img_laplacian)    # 计算绝对值，并将结果转换成 8 位\n",
    "    \n",
    "    cv2.imshow(WIN_NAME, img_abs)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"size\", WIN_NAME, 1, 10, on_laplacian)\n",
    "cv2.createTrackbar(\"ksize\", WIN_NAME, 1, 3, on_laplacian)\n",
    "cv2.createTrackbar(\"scale\", WIN_NAME, 10, 100, on_laplacian)\n",
    "cv2.createTrackbar(\"delta\", WIN_NAME, 0, 100, on_laplacian)\n",
    "on_laplacian(0)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 - 霍夫变换\n",
    "\n",
    "霍夫变换是识别图像几何形状的基本方法之一，用于快速准确地检测出图中的直线或(椭)圆。在使用霍夫变换之前，首先要对图像进行边缘检测。\n",
    "\n",
    "它是图像处理中的一种特征提取技术，该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合，作为霍夫变换的结果。\n",
    "\n",
    "霍夫变换将 在一个空间中具有相同形状的曲线或直线 映射到 另一个坐标空间的一个点上 形成峰值，从而把检测任意形状的问题转化为统计峰值问题。\n",
    "\n",
    "##### 7.2.3 - 霍夫线变换的原理\n",
    "\n",
    "OpenCV 中通过两个函数来支持三种不同的霍夫线变换：\n",
    "\n",
    "- HoughLines()\n",
    "  - 标准霍夫变换 Standard Hough Transform, SHT\n",
    "  - 多尺度霍夫变换 Multi-Scale Hough Transform, MSHT\n",
    "    - SHT 在多尺度下的一个变种\n",
    "- HoughLinesP()\n",
    "  - 累计概率霍夫变换 Progressive Probabilistic Hough Transform, PPHT\n",
    "    - SHT 的一个改进\n",
    "    - 在一定范围内进行霍夫变换，计算单独线段的方向以及范围，从而减少计算量、缩短计算时间，执行效率更高\n",
    "\n",
    "霍夫线变换的原理：\n",
    "\n",
    "1) 采用极坐标系表示直线。则直线的表达式可为：\n",
    "\n",
    "$$ y = (-\\frac{cos\\theta}{sin\\theta}) x + (\\frac{r}{sin\\theta}) $$\n",
    "\n",
    "化简得到：\n",
    "\n",
    "$$ r = x \\cdot cos\\theta + y \\cdot sin\\theta $$\n",
    "\n",
    "2) 对于点 $(x_{0}, y_{0})$，可以将通过这个点的一族直线统一定义为：\n",
    "\n",
    "$$ r_{\\theta} = x_{0} \\cdot cos\\theta + y_{0} \\cdot sin\\theta $$\n",
    "\n",
    "这意味着每一对 $(r_{\\theta}, \\theta)$ 代表一条通过点 $(x_{0}, y_{0})$ 的直线\n",
    "\n",
    "3) 如果对于一个给定点 $(x_{0}, y_{0})$，在极坐标系上，对极径极角平面绘出所有通过它的直线，将得到一条正弦曲线。\n",
    "\n",
    "4) 对图像中所有点进行上述操作，如果两个不同点所对应的曲线在平面 $\\theta-r$ 相交，则意味着它们通过同一条直线\n",
    "\n",
    "<center>\n",
    "    <img src=\"image_host/2022-01-31-12-05-45.png\" alt=\"\"></img>\n",
    "    <div></div>\n",
    "</center>\n",
    "\n",
    "5) 通过设置曲线数量阈值来定义多少条曲线相交于一点，才认为检测到了一条直线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准霍夫变换 SHT & 累计概率霍夫变换 PPHT\n",
    "img = cv2.imread(\"./image/61_HoughLines.jpg\")\n",
    "WIN_NAME = \"Hough Lines\"\n",
    "gray = cv2.Canny(img, threshold1=50, threshold2=200, edges=3)\n",
    "\n",
    "\n",
    "def on_hough_lines(_):\n",
    "    mode = cv2.getTrackbarPos(\"mode\", WIN_NAME)\n",
    "    thres = cv2.getTrackbarPos(\"thres\", WIN_NAME)\n",
    "    srn = cv2.getTrackbarPos(\"srn\", WIN_NAME)\n",
    "    stn = cv2.getTrackbarPos(\"stn\", WIN_NAME)\n",
    "    mll = cv2.getTrackbarPos(\"minLineLength\", WIN_NAME)\n",
    "    mlg = cv2.getTrackbarPos(\"maxLineGap\", WIN_NAME)\n",
    "    if srn == 0 or stn == 0:\n",
    "        srn = stn = 0\n",
    "    \n",
    "    if mode == 0:   # SHT\n",
    "        \"\"\"\n",
    "        lines:      数组，输出检测到的线条，每条线由矢量 (ρ, θ) 表示\n",
    "        rho:        double 类型，以像素为单位的距离精度\n",
    "        theta:      double 类型，以弧度为单位的角度精度\n",
    "        threshold:  int 类型，累加平面的阈值参数，即识别某部分为图中的一条直线时它在累加平面中必须达到的值。\n",
    "                    大于阈值的线段才可以被检测通过并返回到结果中。\n",
    "        srn:        double 类型，默认为 0。对于多尺度霍夫变换，表示 rho 的除数距离，\n",
    "                    粗略的累加器进步尺寸直接是 rho，而精确的为 rho/srn\n",
    "        stn:        double 类型，默认为 0。对于多尺度霍夫变换，表示 theta 的除数距离，\n",
    "\n",
    "        如果 srn 和 stn 同时为 0，就表示用标准霍夫变换，否则这两个参数都应该为正数\n",
    "        \"\"\"\n",
    "        lines = cv2.HoughLines(gray, rho=1, theta=np.pi/180, threshold=thres, srn=srn, stn=stn)\n",
    "\n",
    "        bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        if lines is not None:\n",
    "            for i in range(lines.shape[0]): # 依次在图中绘制出每条线段\n",
    "                rho = lines[i][0][0]\n",
    "                theta = lines[i][0][1]\n",
    "                a = np.cos(theta)\n",
    "                b = np.sin(theta)\n",
    "                x0 = a*rho\n",
    "                y0 = b*rho\n",
    "                pt1 = (int(round(x0 + 1000*(-b))), int(round(y0 + 1000*(a))))\n",
    "                pt2 = (int(round(x0 - 1000*(-b))), int(round(y0 - 1000*(a))))\n",
    "                cv2.line(bgr, pt1, pt2, color=(55, 100, 195), thickness=1, lineType=cv2.LINE_AA)\n",
    "                \n",
    "    else:\n",
    "        \"\"\"\n",
    "        lines:          输出被检测线段的起点和终点的坐标\n",
    "        minLineLength:  double 类型，默认为 0。表示最低线段的长度，否则不显示\n",
    "        maxLineGap:     double 类型，默认为 0。允许将同一行点与点之间连接起来的最大距离\n",
    "        \"\"\"\n",
    "        lines = cv2.HoughLinesP(gray, rho=1, theta=np.pi/180, threshold=thres, minLineLength=mll, maxLineGap=mlg) # PPHT\n",
    "\n",
    "        bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        if lines is not None:\n",
    "            for i in range(lines.shape[0]):\n",
    "                start = (lines[i][0][0], lines[i][0][1])\n",
    "                end = (lines[i][0][2], lines[i][0][3])\n",
    "                cv2.line(bgr, pt1=start, pt2=end, color=(186, 88, 255), thickness=1, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    result = np.hstack([img, bgr])\n",
    "    cv2.imshow(WIN_NAME, result)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME, 0)\n",
    "cv2.createTrackbar(\"mode\", WIN_NAME, 1, 1, on_hough_lines)\n",
    "cv2.createTrackbar(\"thres\", WIN_NAME, 150, 1000, on_hough_lines)\n",
    "cv2.createTrackbar(\"srn\", WIN_NAME, 0, 50, on_hough_lines)\n",
    "cv2.createTrackbar(\"stn\", WIN_NAME, 0, 50, on_hough_lines)\n",
    "cv2.createTrackbar(\"minLineLength\", WIN_NAME, 50, 50, on_hough_lines)\n",
    "cv2.createTrackbar(\"maxLineGap\", WIN_NAME, 10, 50, on_hough_lines)\n",
    "on_hough_lines(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2.6 - 霍夫圆变换\n",
    "\n",
    "直线可以由 极径、极角 $(r, \\theta)$ 来表示，而圆则是由 圆心和半径 $(x_{center}, y_{center}, r)$ 来唯一确定。常常通过“霍夫梯度法”来解决圆变换问题。\n",
    "\n",
    "##### 7.2.7 - 霍夫梯度法原理\n",
    "\n",
    "1. 首先对图像应用边缘检测，比如用 canny 边缘检测。\n",
    "2. 然后，对边缘图像中的每一个非零点，考虑其局部梯度，即用 Sobel() 函数计算x和y方向的 Sobel 一阶导数得到梯度。\n",
    "3. 利用得到的梯度，由斜率指定的直线上的每一个点都在累加器中被累加，这里的斜率是从一个指定的最小值到指定的最大值的距离。\n",
    "4. 同时，标记边缘图像中每一个非 0 像素的位置。\n",
    "5. 然后从二维累加器中这些点中选择候选的中心，这些中心都大于给定阈值并且大于其所有近邻。这些候选的中心按照累加值降序排列，以便于最支持像素的中心首先出现。\n",
    "6. 接下来对每一个中心，考虑所有的非 0 像素。\n",
    "7. 这些像素按照其与中心的距离排序。从到最大半径的最小距离算起，选择非 0 像素最支持的一条半径。\n",
    "8. 如果一个中心受到边缘图像非 0 像素最充分的支持，并且到前期被选择的中心有足够的距离，那么它就会被保留下来。\n",
    "\n",
    "- 优点\n",
    "  - 帮助解决三维累加器中会产生许多稀疏分布的噪声，并使结果不稳定的问题\n",
    "- 缺点\n",
    "  - Sobel 导数所求取的局部梯度并不稳定\n",
    "  - 边缘图像的所有非 0 像素都会成为候选，如果阈值偏低，将会消耗大量计算时间\n",
    "  - 每个中心只能选择一个圆，无法解决同心圆问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 霍夫圆变换\n",
    "img = cv2.imread(\"./image/63_HoughCircles.jpg\")\n",
    "WIN_NAME = \"Hough Circle\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, ksize=(9, 9), sigmaX=2, sigmaY=2)\n",
    "\n",
    "\n",
    "def on_hough_circle(_):\n",
    "    dp = cv2.getTrackbarPos(\"dp\", WIN_NAME) * 0.1 + 0.1\n",
    "    md = cv2.getTrackbarPos(\"minDist\", WIN_NAME) + 1\n",
    "    p1 = cv2.getTrackbarPos(\"param1\", WIN_NAME) + 1\n",
    "    p2 = cv2.getTrackbarPos(\"param2\", WIN_NAME) + 1\n",
    "    minR = cv2.getTrackbarPos(\"minRadius\", WIN_NAME)\n",
    "    maxR = cv2.getTrackbarPos(\"maxRadius\", WIN_NAME)\n",
    "    \n",
    "    \"\"\"\n",
    "    circles:    double 类型，输出矢量数组，每个浮点矢量包含圆心坐标和半径\n",
    "    method:     使用的检测方法，OpenCV 目前只支持霍夫梯度法，即 HOUGH_GRADIENT\n",
    "    dp:         double 类型，检测圆心的累加器图像和输入图像的分辨率之比的倒数\n",
    "    minDist:    double 类型，霍夫变换所检测到的圆的圆心之间的最小距离\n",
    "    param1:     double 类型，默认为 100。method 的对应参数，表示传递给边缘检测算子的高阈值，低阈值为高阈值的一半\n",
    "    param2:     double 类型，默认为 100。method 的对应参数，表示在检测阶段圆心的累加器阈值。值越小，越可以检测到更多不存在的圆；值越大，检测到的圆就越接近完美圆形。\n",
    "    minRadius:  int 类型，默认为 0。表示圆半径的最小值\n",
    "    maxRadius:  int 类型，默认为 0。表示圆半径的最大值。\n",
    "                如果 <= 0，则使用最大图像尺寸。如果 < 0，HOUGH_GRADIENT 返回中心而不找到半径\n",
    "    \"\"\"\n",
    "    circles = cv2.HoughCircles(\n",
    "        gray, method=cv2.HOUGH_GRADIENT, dp=dp, minDist=md, \n",
    "        param1=p1, param2=p2, minRadius=minR, maxRadius=maxR)\n",
    "    \n",
    "    bgr = img.copy()\n",
    "    if circles is not None:\n",
    "        for i in range(circles.shape[1]):\n",
    "            center = (int(round(circles[0][i][0])), int(round(circles[0][i][1])))\n",
    "            radius = int(round(circles[0][i][2]))\n",
    "            cv2.circle(bgr, center=center, radius=radius, color=(255, 0, 0), thickness=3, lineType=8, shift=0)\n",
    "    cv2.imshow(WIN_NAME, bgr)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME, 0)\n",
    "cv2.createTrackbar(\"dp\", WIN_NAME, 14, 20, on_hough_circle)\n",
    "cv2.createTrackbar(\"minDist\", WIN_NAME, 9, 100, on_hough_circle)\n",
    "cv2.createTrackbar(\"param1\", WIN_NAME, 199, 500, on_hough_circle)\n",
    "cv2.createTrackbar(\"param2\", WIN_NAME, 99, 500, on_hough_circle)\n",
    "cv2.createTrackbar(\"minRadius\", WIN_NAME, 0, 10, on_hough_circle)\n",
    "cv2.createTrackbar(\"maxRadius\", WIN_NAME, 0, 10, on_hough_circle)\n",
    "on_hough_circle(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 - 重映射 - remap()\n",
    "\n",
    "重映射是指将一幅图像中某位置的像素放置到另一个图片指定位置的过程，例如图片镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1059, 2012, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./image/65_remap.jpg\")\n",
    "print(img.shape)\n",
    "rows = img.shape[0]\n",
    "cols = img.shape[1]\n",
    "\n",
    "# 左右对称\n",
    "\"\"\"\n",
    "[[5. 4. 3. 2. 1.]\n",
    " [5. 4. 3. 2. 1.]\n",
    " [5. 4. 3. 2. 1.]]\n",
    "[[0. 0. 0. 0. 0.]\n",
    " [1. 1. 1. 1. 1.]\n",
    " [2. 2. 2. 2. 2.]]\n",
    "\"\"\"\n",
    "hor_x = np.zeros((rows, cols), dtype=np.float32)\n",
    "hor_y = np.zeros((rows, cols), dtype=np.float32)\n",
    "for i in range(rows):\n",
    "    hor_x[i, :] = [cols-x for x in range(cols)]\n",
    "for j in range(cols):\n",
    "    hor_y[:, j] = [y for y in range(rows)]\n",
    "\n",
    "# 上下对称\n",
    "\"\"\"\n",
    "[[0. 1. 2. 3. 4.]\n",
    " [0. 1. 2. 3. 4.]\n",
    " [0. 1. 2. 3. 4.]]\n",
    "[[3. 3. 3. 3. 3.]\n",
    " [2. 2. 2. 2. 2.]\n",
    " [1. 1. 1. 1. 1.]]\n",
    "\"\"\"\n",
    "ver_x = np.zeros((rows, cols), dtype=np.float32)\n",
    "ver_y = np.zeros((rows, cols), dtype=np.float32)\n",
    "for i in range(rows):\n",
    "    ver_x[i, :] = [x for x in range(cols)]\n",
    "for j in range(cols):\n",
    "    ver_y[:, j] = [rows-y for y in range(rows)]\n",
    "\n",
    "# 中心对称\n",
    "\"\"\"\n",
    "[[5. 4. 3. 2. 1.]\n",
    " [5. 4. 3. 2. 1.]\n",
    " [5. 4. 3. 2. 1.]]\n",
    "[[3. 3. 3. 3. 3.]\n",
    " [2. 2. 2. 2. 2.]\n",
    " [1. 1. 1. 1. 1.]]\n",
    "\"\"\"\n",
    "cen_x = np.zeros((rows, cols), dtype=np.float32)\n",
    "cen_y = np.zeros((rows, cols), dtype=np.float32)\n",
    "for i in range(rows):\n",
    "    cen_x[i, :] = [cols-x for x in range(cols)]\n",
    "for j in range(cols):\n",
    "    cen_y[:, j] = [rows-y for y in range(rows)]\n",
    "\n",
    "# 尺度缩放\n",
    "\"\"\"\n",
    "[[0. 0. 0. 0. 0.]\n",
    " [0. 0. 2. 4. 0.]\n",
    " [0. 0. 2. 4. 0.]]\n",
    "[[0. 0. 0. 0. 0.]\n",
    " [0. 0. 1. 1. 0.]\n",
    " [0. 0. 3. 3. 0.]]\n",
    "\"\"\"\n",
    "scale_x = np.zeros((rows, cols), dtype=np.float32)\n",
    "scale_y = np.zeros((rows, cols), dtype=np.float32)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        if cols*0.25 < j < cols*0.75 and rows*0.25 < i < rows*0.75:\n",
    "            scale_x[i][j] = 2*(j-cols*0.25)+0.5\n",
    "            scale_y[i][j] = 2*(i-rows*0.25)+0.5\n",
    "        else:\n",
    "            scale_x[i][j] = 0\n",
    "            scale_y[i][j] = 0\n",
    "\n",
    "\n",
    "def my_remap(src, map_x, map_y):\n",
    "    return cv2.remap(src=src, \n",
    "        map1=map_x, map2=map_y, \n",
    "        interpolation=cv2.INTER_LINEAR, # resize() 函数有提到，五种插值方式中 INTER_AREA 不支持\n",
    "        borderMode=cv2.BORDER_CONSTANT, # 边界模式，默认为 BORDER_CONSTANT，表示目标图像中 离群点(outliers) 的像素值不会被此函数修改\n",
    "        borderValue=(0, 0, 0))  # 当有常数边界时使用，默认为 (0, 0, 0)\n",
    "\n",
    "\n",
    "horizontal = my_remap(img, hor_x, hor_y)\n",
    "vertical = my_remap(img, ver_x, ver_y)\n",
    "reverse = my_remap(img, cen_x, cen_y)\n",
    "scale = my_remap(reverse, scale_x, scale_y)\n",
    "\n",
    "cv2.namedWindow(\"Remap\", 0)\n",
    "col1 = np.vstack([img, vertical])\n",
    "col2 = np.vstack([horizontal, reverse])\n",
    "result1 = np.hstack([col1, col2])\n",
    "cv2.imshow(\"Remap\", result1)\n",
    "\n",
    "cv2.namedWindow(\"Scale\", 0)\n",
    "result2 = np.hstack([reverse, scale])\n",
    "cv2.imshow(\"Scale\", result2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 - 仿射变换\n",
    "\n",
    "Affine Transformation 是指一个向量空间进行一次线性变换并接上一个平移，变换为另一个向量空间的过程。它保持了二维图形的【平直性】和【平行性】。\n",
    "\n",
    "任意一个仿射变换都能表示为乘以一个矩阵（线性变换）接着再加上一个向量（平移）的形式：\n",
    "\n",
    "- 线性变换\n",
    "  - 旋转\n",
    "  - 缩放\n",
    "- 向量加\n",
    "  - 平移\n",
    "\n",
    "仿射变换涉及到 warpAffine() 和 getRotationMatrix2D() 这两个函数：\n",
    "\n",
    "- warpAffine() 实现一些简单的重映射\n",
    "- getRotationMatrix2D() 获得旋转矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Transformation\n",
    "img = cv2.imread(\"./image/1_HelloOpenCV.jpg\")\n",
    "rows = img.shape[0]\n",
    "cols = img.shape[1]\n",
    "\n",
    "## 设置原图像 SouRCe 和目标图像 DeSTination 上的三组点以计算仿射变换\n",
    "# 定义两个三角形\n",
    "src_triangle = np.zeros((3, 2), dtype=np.float32)\n",
    "dst_triangle = np.zeros((3, 2), dtype=np.float32)\n",
    "\n",
    "src_triangle[0] = (0, 0)\n",
    "src_triangle[1] = (cols - 1, 0)\n",
    "src_triangle[2] = (0, rows - 1)\n",
    "\n",
    "dst_triangle[0] = (cols*0.00, rows*0.33)\n",
    "dst_triangle[1] = (cols*0.65, rows*0.35)\n",
    "dst_triangle[2] = (cols*0.15, rows*0.60)\n",
    "\n",
    "# 求得仿射变换\n",
    "map_warp = cv2.getAffineTransform(src_triangle, dst_triangle)\n",
    "\n",
    "# 对原图像应用刚刚求得的仿射变换\n",
    "dst_warp = cv2.warpAffine(img, map_warp, (cols, rows))\n",
    "\n",
    "## 对图像进行缩放后再旋转\n",
    "# 计算绕图像中点顺时针旋转 30°、缩放因子为 0.8 的旋转矩阵\n",
    "center = (dst_warp.shape[1]/2, dst_warp.shape[0]/2)\n",
    "angle = -30.0   # Positive values mean counter-clockwise rotation\n",
    "scale = 0.8\n",
    "map_rot = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "# 旋转已缩放后的图像\n",
    "dst_warp_rot = cv2.warpAffine(dst_warp, map_rot, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"Affine Transformation\", dst_warp_rot)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 - 直方图均衡化\n",
    "\n",
    "用于扩大图像的动态范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# 直方图均衡化\n",
    "img = cv2.imread(\"./image/68_equalizeHist.jpg\")\n",
    "print(img.dtype)\n",
    "\n",
    "blue, green, red = cv2.split(img)   # 对各个通道分别做直方图均衡化\n",
    "blue = cv2.equalizeHist(blue)   # 只能输入 8 位单通道图像\n",
    "green = cv2.equalizeHist(green)\n",
    "red = cv2.equalizeHist(red)\n",
    "dst = cv2.merge([blue, green, red])\n",
    "\n",
    "result = np.hstack([img, dst])\n",
    "cv2.imshow(\"Equalize Histogram\", result)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第八章 - 图像轮廓与图像分割修复\n",
    "\n",
    "#### 8.1 - 查找并绘制轮廓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./image/69_findContours.jpg\")\n",
    "WIN_NAME = \"Find and draw the contours of image\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # 灰度图\n",
    "\n",
    "## findContours() 函数可选的\n",
    "# 轮廓检索模式\n",
    "modes = [cv2.RETR_EXTERNAL,   # 只检测最外层的轮廓\n",
    "         cv2.RETR_LIST,       # 提取所有轮廓，并且放置在 list 中。检测的轮廓不建立等级关系\n",
    "         cv2.RETR_CCOMP,      # 提取所有轮廓，并且将其组织为双层结构：顶层为连通域的外围边界，次层为孔的内层边界\n",
    "         cv2.RETR_TREE]       # 提取所有轮廓，并重新建立网状的轮廓结构\n",
    "# 轮廓近似办法\n",
    "methods = [cv2.CHAIN_APPROX_NONE,       # 获取每个轮廓的每个像素，相邻的两个点的像素位置差不超过 1\n",
    "           cv2.CHAIN_APPROX_SIMPLE,     # 压缩水平、垂直、对角线方向的元素，只保留该方向的终点坐标。例如用四个点表示一个矩形\n",
    "           cv2.CHAIN_APPROX_TC89_L1,    # 使用 Teh-Chin1 链逼近算法中的一个\n",
    "           cv2.CHAIN_APPROX_TC89_KCOS]\n",
    "\n",
    "\n",
    "def on_contours(_):\n",
    "    t = cv2.getTrackbarPos(\"threshold\", WIN_NAME)\n",
    "    idx_mode = cv2.getTrackbarPos(\"modes index\", WIN_NAME)\n",
    "    idx_method = cv2.getTrackbarPos(\"methods index\", WIN_NAME)\n",
    "    tn = cv2.getTrackbarPos(\"thickness\", WIN_NAME) - 1\n",
    "    lt = (cv2.getTrackbarPos(\"line type\", WIN_NAME) + 1) * 4\n",
    "    ml = cv2.getTrackbarPos(\"max level\", WIN_NAME)\n",
    "    dx = cv2.getTrackbarPos(\"dx\", WIN_NAME)\n",
    "    dy = cv2.getTrackbarPos(\"dy\", WIN_NAME)\n",
    "    \n",
    "    # _, src = cv2.threshold(gray, thresh=t, maxval=255, type=cv2.THRESH_BINARY)  # 取图片中阈值大于 t 的部分\n",
    "    src = cv2.Canny(gray, threshold1=t, threshold2=t*2, apertureSize=3)\n",
    "    dst = np.zeros(img.shape, img.dtype)\n",
    "    \n",
    "    # 寻找轮廓 - findContours()\n",
    "    \"\"\"\n",
    "    contours    将检测到的轮廓信息以点向量形式储存\n",
    "    hierarchy   可选的输出变量，包含图像的拓扑信息。\n",
    "                每个 contour 对应 4 个 hierarchy 元素，\n",
    "                分别表示后一个轮廓、前一个轮廓、父轮廓、内嵌轮廓的索引编号。如果没有对应值，则设为负数\n",
    "    \"\"\"\n",
    "    contours, hierarchy = cv2.findContours(src, mode=modes[idx_mode], method=methods[idx_method])\n",
    "\n",
    "    # 绘制轮廓 - drawContours()\n",
    "    for idx in range(len(contours)):\n",
    "        color = (np.random.randint(255), np.random.randint(255), np.random.randint(255))\n",
    "        cv2.drawContours(dst,       # 输出图像\n",
    "            contours=contours,\n",
    "            contourIdx=idx,         # 轮廓绘制的指示变量。如果为负值，则绘制所有轮廓\n",
    "            color=color,            # 轮廓颜色\n",
    "            thickness=tn,           # 轮廓线条粗细，默认为 1；若为负值(cv2.FILLED)，则绘制在轮廓的内部\n",
    "            lineType=lt,            # 线条类型，默认为 8 【8 - 八联通，4 - 四联通，LINE_AA(16) - 抗锯齿线性】\n",
    "            hierarchy=hierarchy,    # 可选的层次结构信息\n",
    "            maxLevel=ml,            # 用于绘制轮廓的最大等级，默认为 INTER_MAX(7)。如果为 0，则仅绘制指定的轮廓。如果为 1，该函数将绘制轮廓和所有嵌套轮廓。如果为 2，函数将绘制等高线、所有嵌套等高线、所有嵌套到嵌套的等高线，依此类推。仅当存在可用的层次结构时，才会考虑此参数。\n",
    "            offset=(dx, dy))        # 指定所绘制的轮廓所需的偏移量，默认为 (0, 0)\n",
    "\n",
    "    result = np.hstack([img, dst])\n",
    "    cv2.imshow(\"Find and draw the contours of image\", result)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME, 0)\n",
    "cv2.createTrackbar(\"threshold\", WIN_NAME, 119, 255, on_contours)\n",
    "cv2.createTrackbar(\"modes index\", WIN_NAME, 0, len(modes)-1, on_contours)\n",
    "cv2.createTrackbar(\"methods index\", WIN_NAME, 0, len(methods)-1, on_contours)\n",
    "cv2.createTrackbar(\"thickness\", WIN_NAME, 0, 20, on_contours)\n",
    "cv2.createTrackbar(\"line type\", WIN_NAME, 0, 2, on_contours)\n",
    "cv2.createTrackbar(\"max level\", WIN_NAME, 7, 7, on_contours)\n",
    "cv2.createTrackbar(\"dx\", WIN_NAME, 0, 20, on_contours)\n",
    "cv2.createTrackbar(\"dy\", WIN_NAME, 0, 20, on_contours)\n",
    "on_contours(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 - 寻找物体的凸包\n",
    "\n",
    "给定二维平面上的点集，凸包 (convex hull) 是指由最外层的点所连接构成的凸多边形。\n",
    "\n",
    "理解物体形状或轮廓的一种比较有用的方法便是计算一个物体的凸包，然后计算其凸缺陷 (convexity defects)，许多复杂物体的特性可以被这种缺陷很好地表现出来。\n",
    "\n",
    "![img](image_host/2022-02-24-23-46-17.png)\n",
    "\n",
    "比如上图中 A 到 H 表示人手图的凸缺陷。这些凸缺陷提供了手及其状态的特征表现方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./image/72_convexHull.jpg\")\n",
    "WIN_NAME = \"Find the convex hull of stuff\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # 灰度图\n",
    "\n",
    "\n",
    "def on_convex_hull(_):\n",
    "    t = cv2.getTrackbarPos(\"threshold\", WIN_NAME)\n",
    "    \n",
    "    _, src = cv2.threshold(gray, thresh=t, maxval=255, type=cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(src, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    hull = []\n",
    "    for i in range(len(contours)):\n",
    "        hull.append(cv2.convexHull(contours[i], clockwise=False))\n",
    "    \n",
    "    dst = np.zeros(img.shape, img.dtype)\n",
    "    cv2.drawContours(dst, hull, -1, (255, 255, 255), 1, 8, hierarchy, 7, (0, 0))\n",
    "    result = np.hstack([img, dst])\n",
    "    cv2.imshow(WIN_NAME, result)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"threshold\", WIN_NAME, 190, 255, on_convex_hull)\n",
    "on_convex_hull(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 - 使用多边形将轮廓包围\n",
    "\n",
    "##### 8.3.6/7 - 创建包围轮廓的矩形/圆形边界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((600, 600, 3), dtype=\"uint8\")\n",
    "WIN_NAME = \"create the bounding of contour\"\n",
    "rows = img.shape[0]\n",
    "cols = img.shape[1]\n",
    "count = np.random.randint(3, 103)   # 随机生成点的数量\n",
    "points = np.zeros([count, 2], dtype=\"float32\")\n",
    "for i in range(count):\n",
    "    # 生成随机坐标\n",
    "    points[i] = [np.random.randint(cols/4, cols*3/4),\n",
    "        np.random.randint(rows/4, rows*3/4)]\n",
    "    # 绘制随机点\n",
    "    color = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "    cv2.circle(img,\n",
    "        center=tuple(points[i].astype(int)),\n",
    "        radius=3,\n",
    "        color=color,\n",
    "        thickness=cv2.FILLED,\n",
    "        lineType=cv2.LINE_AA)\n",
    "\n",
    "color = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "\n",
    "\n",
    "def on_bounding(_):\n",
    "    mode = cv2.getTrackbarPos(\"mode\", WIN_NAME)\n",
    "    \n",
    "    src = img.copy()\n",
    "    if mode == 0:\n",
    "        # 对给定的二维点集，寻找最小面积的包围矩形\n",
    "        rect = cv2.minAreaRect(points)\n",
    "        # 绘制出最小面积的包围矩形\n",
    "        box = cv2.boxPoints(rect)\n",
    "        for i in range(4):\n",
    "            cv2.line(src,\n",
    "                pt1=tuple(box[i].astype(int)),\n",
    "                pt2=tuple(box[(i+1) % 4].astype(int)),\n",
    "                color=color,\n",
    "                thickness=2,\n",
    "                lineType=cv2.LINE_AA)\n",
    "    else:\n",
    "        # 对给定的二维点集，寻找最小面积的包围圈\n",
    "        center, radius = cv2.minEnclosingCircle(points)\n",
    "        # 绘制出最小面积的包围圈\n",
    "        for i in range(count):\n",
    "            cv2.circle(src,\n",
    "                center=(int(center[0]), int(center[1])),\n",
    "                radius=int(radius),\n",
    "                color=color,\n",
    "                thickness=2,\n",
    "                lineType=cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(WIN_NAME, src)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"mode\", WIN_NAME, 0, 1, on_bounding)\n",
    "on_bounding(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4 - 图像的矩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出内容：面积和轮廓长度\n",
      "通过 m00 计算出轮廓 0 的面积： 2.0\n",
      "OpenCV 函数计算出的面积：-2.00，长度：18.49\n",
      "通过 m00 计算出轮廓 1 的面积： 5.0\n",
      "OpenCV 函数计算出的面积：-5.00，长度：29.80\n",
      "通过 m00 计算出轮廓 2 的面积： 11.0\n",
      "OpenCV 函数计算出的面积：-11.00，长度：13.66\n",
      "通过 m00 计算出轮廓 3 的面积： 8.0\n",
      "OpenCV 函数计算出的面积：8.00，长度：11.31\n",
      "通过 m00 计算出轮廓 4 的面积： 12.0\n",
      "OpenCV 函数计算出的面积：-12.00，长度：75.25\n",
      "通过 m00 计算出轮廓 5 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：22.24\n",
      "通过 m00 计算出轮廓 6 的面积： 7.0\n",
      "OpenCV 函数计算出的面积：-7.00，长度：47.11\n",
      "通过 m00 计算出轮廓 7 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：47.90\n",
      "通过 m00 计算出轮廓 8 的面积： 13.5\n",
      "OpenCV 函数计算出的面积：-13.50，长度：14.24\n",
      "通过 m00 计算出轮廓 9 的面积： 9.5\n",
      "OpenCV 函数计算出的面积：9.50，长度：11.90\n",
      "通过 m00 计算出轮廓 10 的面积： 7.0\n",
      "OpenCV 函数计算出的面积：-7.00，长度：81.60\n",
      "通过 m00 计算出轮廓 11 的面积： 5.0\n",
      "OpenCV 函数计算出的面积：-5.00，长度：20.14\n",
      "通过 m00 计算出轮廓 12 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：21.90\n",
      "通过 m00 计算出轮廓 13 的面积： 12.0\n",
      "OpenCV 函数计算出的面积：-12.00，长度：13.66\n",
      "通过 m00 计算出轮廓 14 的面积： 8.5\n",
      "OpenCV 函数计算出的面积：8.50，长度：11.07\n",
      "通过 m00 计算出轮廓 15 的面积： 13.0\n",
      "OpenCV 函数计算出的面积：-13.00，长度：34.63\n",
      "通过 m00 计算出轮廓 16 的面积： 8.0\n",
      "OpenCV 函数计算出的面积：8.00，长度：11.31\n",
      "通过 m00 计算出轮廓 17 的面积： 1.5\n",
      "OpenCV 函数计算出的面积：-1.50，长度：17.07\n",
      "通过 m00 计算出轮廓 18 的面积： 61.0\n",
      "OpenCV 函数计算出的面积：-61.00，长度：232.19\n",
      "通过 m00 计算出轮廓 19 的面积： 12.0\n",
      "OpenCV 函数计算出的面积：-12.00，长度：187.20\n",
      "通过 m00 计算出轮廓 20 的面积： 3.0\n",
      "OpenCV 函数计算出的面积：-3.00，长度：34.97\n",
      "通过 m00 计算出轮廓 21 的面积： 4.0\n",
      "OpenCV 函数计算出的面积：-4.00，长度：32.97\n",
      "通过 m00 计算出轮廓 22 的面积： 16.0\n",
      "OpenCV 函数计算出的面积：-16.00，长度：460.45\n",
      "通过 m00 计算出轮廓 23 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：99.21\n",
      "通过 m00 计算出轮廓 24 的面积： 1.0\n",
      "OpenCV 函数计算出的面积：-1.00，长度：139.60\n",
      "通过 m00 计算出轮廓 25 的面积： 8.0\n",
      "OpenCV 函数计算出的面积：-8.00，长度：125.74\n",
      "通过 m00 计算出轮廓 26 的面积： 30.5\n",
      "OpenCV 函数计算出的面积：-30.50，长度：202.21\n",
      "通过 m00 计算出轮廓 27 的面积： 4.0\n",
      "OpenCV 函数计算出的面积：-4.00，长度：48.14\n",
      "通过 m00 计算出轮廓 28 的面积： 26.0\n",
      "OpenCV 函数计算出的面积：-26.00，长度：114.51\n",
      "通过 m00 计算出轮廓 29 的面积： 27.0\n",
      "OpenCV 函数计算出的面积：-27.00，长度：118.51\n",
      "通过 m00 计算出轮廓 30 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：31.90\n",
      "通过 m00 计算出轮廓 31 的面积： 8.5\n",
      "OpenCV 函数计算出的面积：-8.50，长度：74.53\n",
      "通过 m00 计算出轮廓 32 的面积： 28.0\n",
      "OpenCV 函数计算出的面积：-28.00，长度：844.27\n",
      "通过 m00 计算出轮廓 33 的面积： 2.0\n",
      "OpenCV 函数计算出的面积：-2.00，长度：15.66\n",
      "通过 m00 计算出轮廓 34 的面积： 141.5\n",
      "OpenCV 函数计算出的面积：-141.50，长度：513.19\n",
      "通过 m00 计算出轮廓 35 的面积： 8.0\n",
      "OpenCV 函数计算出的面积：-8.00，长度：220.71\n",
      "通过 m00 计算出轮廓 36 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：253.56\n",
      "通过 m00 计算出轮廓 37 的面积： 9.5\n",
      "OpenCV 函数计算出的面积：-9.50，长度：75.50\n",
      "通过 m00 计算出轮廓 38 的面积： 51.5\n",
      "OpenCV 函数计算出的面积：-51.50，长度：190.47\n",
      "通过 m00 计算出轮廓 39 的面积： 37.0\n",
      "OpenCV 函数计算出的面积：37.00，长度：29.80\n",
      "通过 m00 计算出轮廓 40 的面积： 34.5\n",
      "OpenCV 函数计算出的面积：-34.50，长度：165.87\n",
      "通过 m00 计算出轮廓 41 的面积： 27.5\n",
      "OpenCV 函数计算出的面积：-27.50，长度：165.04\n",
      "通过 m00 计算出轮廓 42 的面积： 53.5\n",
      "OpenCV 函数计算出的面积：-53.50，长度：37.90\n",
      "通过 m00 计算出轮廓 43 的面积： 48.5\n",
      "OpenCV 函数计算出的面积：48.50，长度：35.56\n",
      "通过 m00 计算出轮廓 44 的面积： 1.5\n",
      "OpenCV 函数计算出的面积：-1.50，长度：12.24\n",
      "通过 m00 计算出轮廓 45 的面积： 27.0\n",
      "OpenCV 函数计算出的面积：-27.00，长度：171.54\n",
      "通过 m00 计算出轮廓 46 的面积： 20.5\n",
      "OpenCV 函数计算出的面积：20.50，长度：19.90\n",
      "通过 m00 计算出轮廓 47 的面积： 7.0\n",
      "OpenCV 函数计算出的面积：-7.00，长度：247.54\n",
      "通过 m00 计算出轮廓 48 的面积： 12.5\n",
      "OpenCV 函数计算出的面积：-12.50，长度：204.12\n",
      "通过 m00 计算出轮廓 49 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：102.87\n",
      "通过 m00 计算出轮廓 50 的面积： 16.0\n",
      "OpenCV 函数计算出的面积：-16.00，长度：195.88\n",
      "通过 m00 计算出轮廓 51 的面积： 97.0\n",
      "OpenCV 函数计算出的面积：-97.00，长度：664.87\n",
      "通过 m00 计算出轮廓 52 的面积： 4.5\n",
      "OpenCV 函数计算出的面积：-4.50，长度：158.38\n",
      "通过 m00 计算出轮廓 53 的面积： 0.0\n",
      "OpenCV 函数计算出的面积：0.00，长度：11.66\n",
      "通过 m00 计算出轮廓 54 的面积： 70.0\n",
      "OpenCV 函数计算出的面积：-70.00，长度：833.75\n",
      "通过 m00 计算出轮廓 55 的面积： 10.0\n",
      "OpenCV 函数计算出的面积：10.00，长度：13.31\n",
      "通过 m00 计算出轮廓 56 的面积： 12.5\n",
      "OpenCV 函数计算出的面积：-12.50，长度：59.84\n",
      "通过 m00 计算出轮廓 57 的面积： 5.0\n",
      "OpenCV 函数计算出的面积：-5.00，长度：297.40\n",
      "通过 m00 计算出轮廓 58 的面积： 7.5\n",
      "OpenCV 函数计算出的面积：-7.50，长度：71.01\n",
      "通过 m00 计算出轮廓 59 的面积： 29.0\n",
      "OpenCV 函数计算出的面积：-29.00，长度：317.76\n",
      "通过 m00 计算出轮廓 60 的面积： 0.0\n",
      "OpenCV 函数计算出的面积：0.00，长度：6.83\n",
      "通过 m00 计算出轮廓 61 的面积： 3.5\n",
      "OpenCV 函数计算出的面积：-3.50，长度：25.56\n",
      "通过 m00 计算出轮廓 62 的面积： 3.5\n",
      "OpenCV 函数计算出的面积：-3.50，长度：33.56\n",
      "通过 m00 计算出轮廓 63 的面积： 8.0\n",
      "OpenCV 函数计算出的面积：-8.00，长度：49.94\n",
      "通过 m00 计算出轮廓 64 的面积： 11.5\n",
      "OpenCV 函数计算出的面积：-11.50，长度：167.50\n",
      "通过 m00 计算出轮廓 65 的面积： 11.0\n",
      "OpenCV 函数计算出的面积：-11.00，长度：51.60\n",
      "通过 m00 计算出轮廓 66 的面积： 1.5\n",
      "OpenCV 函数计算出的面积：-1.50，长度：12.24\n",
      "通过 m00 计算出轮廓 67 的面积： 12.5\n",
      "OpenCV 函数计算出的面积：-12.50，长度：86.33\n",
      "通过 m00 计算出轮廓 68 的面积： 3.5\n",
      "OpenCV 函数计算出的面积：-3.50，长度：15.90\n",
      "通过 m00 计算出轮廓 69 的面积： 3.0\n",
      "OpenCV 函数计算出的面积：-3.00，长度：10.49\n",
      "通过 m00 计算出轮廓 70 的面积： 13.5\n",
      "OpenCV 函数计算出的面积：-13.50，长度：60.67\n",
      "通过 m00 计算出轮廓 71 的面积： 34.0\n",
      "OpenCV 函数计算出的面积：-34.00，长度：190.94\n",
      "通过 m00 计算出轮廓 72 的面积： 7.0\n",
      "OpenCV 函数计算出的面积：7.00，长度：10.49\n",
      "通过 m00 计算出轮廓 73 的面积： 17.5\n",
      "OpenCV 函数计算出的面积：-17.50，长度：72.33\n",
      "通过 m00 计算出轮廓 74 的面积： 10.0\n",
      "OpenCV 函数计算出的面积：-10.00，长度：89.40\n",
      "通过 m00 计算出轮廓 75 的面积： 1.5\n",
      "OpenCV 函数计算出的面积：-1.50，长度：6.24\n",
      "通过 m00 计算出轮廓 76 的面积： 95.5\n",
      "OpenCV 函数计算出的面积：-95.50，长度：793.03\n",
      "通过 m00 计算出轮廓 77 的面积： 17.5\n",
      "OpenCV 函数计算出的面积：17.50，长度：17.90\n",
      "通过 m00 计算出轮廓 78 的面积： 0.0\n",
      "OpenCV 函数计算出的面积：0.00，长度：49.66\n",
      "通过 m00 计算出轮廓 79 的面积： 1.5\n",
      "OpenCV 函数计算出的面积：-1.50，长度：14.24\n",
      "通过 m00 计算出轮廓 80 的面积： 7.5\n",
      "OpenCV 函数计算出的面积：-7.50，长度：31.21\n",
      "通过 m00 计算出轮廓 81 的面积： 97.5\n",
      "OpenCV 函数计算出的面积：-97.50，长度：540.34\n",
      "通过 m00 计算出轮廓 82 的面积： 4.5\n",
      "OpenCV 函数计算出的面积：-4.50，长度：57.56\n",
      "通过 m00 计算出轮廓 83 的面积： 1.0\n",
      "OpenCV 函数计算出的面积：-1.00，长度：16.83\n",
      "通过 m00 计算出轮廓 84 的面积： 2.0\n",
      "OpenCV 函数计算出的面积：-2.00，长度：46.49\n",
      "通过 m00 计算出轮廓 85 的面积： 2.0\n",
      "OpenCV 函数计算出的面积：-2.00，长度：105.31\n",
      "通过 m00 计算出轮廓 86 的面积： 1.0\n",
      "OpenCV 函数计算出的面积：-1.00，长度：14.83\n",
      "通过 m00 计算出轮廓 87 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：43.41\n",
      "通过 m00 计算出轮廓 88 的面积： 10.0\n",
      "OpenCV 函数计算出的面积：-10.00，长度：78.08\n",
      "通过 m00 计算出轮廓 89 的面积： 6.0\n",
      "OpenCV 函数计算出的面积：-6.00，长度：59.46\n",
      "通过 m00 计算出轮廓 90 的面积： 2.0\n",
      "OpenCV 函数计算出的面积：-2.00，长度：23.31\n",
      "通过 m00 计算出轮廓 91 的面积： 3.0\n",
      "OpenCV 函数计算出的面积：-3.00，长度：34.14\n",
      "通过 m00 计算出轮廓 92 的面积： 4.5\n",
      "OpenCV 函数计算出的面积：-4.50，长度：23.56\n",
      "通过 m00 计算出轮廓 93 的面积： 5.5\n",
      "OpenCV 函数计算出的面积：-5.50，长度：40.38\n",
      "通过 m00 计算出轮廓 94 的面积： 5.5\n",
      "OpenCV 函数计算出的面积：-5.50，长度：49.21\n",
      "通过 m00 计算出轮廓 95 的面积： 3.0\n",
      "OpenCV 函数计算出的面积：-3.00，长度：69.80\n",
      "通过 m00 计算出轮廓 96 的面积： 2.5\n",
      "OpenCV 函数计算出的面积：-2.50，长度：638.69\n",
      "通过 m00 计算出轮廓 97 的面积： 0.0\n",
      "OpenCV 函数计算出的面积：0.00，长度：1006.28\n",
      "通过 m00 计算出轮廓 98 的面积： 4.5\n",
      "OpenCV 函数计算出的面积：-4.50，长度：28.38\n",
      "通过 m00 计算出轮廓 99 的面积： 0.5\n",
      "OpenCV 函数计算出的面积：-0.50，长度：8.24\n",
      "通过 m00 计算出轮廓 100 的面积： 7.0\n",
      "OpenCV 函数计算出的面积：-7.00，长度：71.94\n",
      "通过 m00 计算出轮廓 101 的面积： 39.0\n",
      "OpenCV 函数计算出的面积：-39.00，长度：32.49\n",
      "通过 m00 计算出轮廓 102 的面积： 7.0\n",
      "OpenCV 函数计算出的面积：7.00，长度：9.66\n",
      "通过 m00 计算出轮廓 103 的面积： 27.0\n",
      "OpenCV 函数计算出的面积：27.00，长度：23.31\n",
      "通过 m00 计算出轮廓 104 的面积： 22.5\n",
      "OpenCV 函数计算出的面积：-22.50，长度：78.67\n",
      "通过 m00 计算出轮廓 105 的面积： 15.5\n",
      "OpenCV 函数计算出的面积：15.50，长度：15.90\n",
      "通过 m00 计算出轮廓 106 的面积： 4.0\n",
      "OpenCV 函数计算出的面积：-4.00，长度：34.97\n",
      "通过 m00 计算出轮廓 107 的面积： 1.5\n",
      "OpenCV 函数计算出的面积：-1.50，长度：10.24\n",
      "通过 m00 计算出轮廓 108 的面积： 12.5\n",
      "OpenCV 函数计算出的面积：-12.50，长度：105.64\n",
      "通过 m00 计算出轮廓 109 的面积： 7.5\n",
      "OpenCV 函数计算出的面积：-7.50，长度：52.04\n",
      "通过 m00 计算出轮廓 110 的面积： 11.5\n",
      "OpenCV 函数计算出的面积：-11.50，长度：97.98\n",
      "通过 m00 计算出轮廓 111 的面积： 3.0\n",
      "OpenCV 函数计算出的面积：-3.00，长度：21.31\n",
      "通过 m00 计算出轮廓 112 的面积： 4.0\n",
      "OpenCV 函数计算出的面积：-4.00，长度：39.80\n",
      "通过 m00 计算出轮廓 113 的面积： 1.5\n",
      "OpenCV 函数计算出的面积：-1.50，长度：35.21\n",
      "通过 m00 计算出轮廓 114 的面积： 8.5\n",
      "OpenCV 函数计算出的面积：-8.50，长度：76.18\n",
      "通过 m00 计算出轮廓 115 的面积： 1.0\n",
      "OpenCV 函数计算出的面积：-1.00，长度：49.31\n",
      "通过 m00 计算出轮廓 116 的面积： 3.0\n",
      "OpenCV 函数计算出的面积：-3.00，长度：30.14\n",
      "通过 m00 计算出轮廓 117 的面积： 15.0\n",
      "OpenCV 函数计算出的面积：-15.00，长度：114.57\n",
      "通过 m00 计算出轮廓 118 的面积： 3.5\n",
      "OpenCV 函数计算出的面积：-3.50，长度：47.56\n",
      "通过 m00 计算出轮廓 119 的面积： 77.5\n",
      "OpenCV 函数计算出的面积：-77.50，长度：569.29\n",
      "通过 m00 计算出轮廓 120 的面积： 7.0\n",
      "OpenCV 函数计算出的面积：7.00，长度：9.66\n",
      "通过 m00 计算出轮廓 121 的面积： 32.0\n",
      "OpenCV 函数计算出的面积：-32.00，长度：161.34\n",
      "通过 m00 计算出轮廓 122 的面积： 10.5\n",
      "OpenCV 函数计算出的面积：10.50，长度：13.90\n",
      "通过 m00 计算出轮廓 123 的面积： 44.0\n",
      "OpenCV 函数计算出的面积：-44.00，长度：303.91\n",
      "通过 m00 计算出轮廓 124 的面积： 7.0\n",
      "OpenCV 函数计算出的面积：-7.00，长度：73.94\n",
      "通过 m00 计算出轮廓 125 的面积： 3.0\n",
      "OpenCV 函数计算出的面积：-3.00，长度：15.31\n",
      "通过 m00 计算出轮廓 126 的面积： 26.0\n",
      "OpenCV 函数计算出的面积：-26.00，长度：395.28\n",
      "通过 m00 计算出轮廓 127 的面积： 54.5\n",
      "OpenCV 函数计算出的面积：-54.50，长度：30.38\n",
      "通过 m00 计算出轮廓 128 的面积： 44.0\n",
      "OpenCV 函数计算出的面积：44.00，长度：28.63\n",
      "通过 m00 计算出轮廓 129 的面积： 6.0\n",
      "OpenCV 函数计算出的面积：-6.00，长度：46.63\n",
      "通过 m00 计算出轮廓 130 的面积： 15.0\n",
      "OpenCV 函数计算出的面积：-15.00，长度：108.57\n",
      "通过 m00 计算出轮廓 131 的面积： 6.5\n",
      "OpenCV 函数计算出的面积：-6.50，长度：58.53\n",
      "通过 m00 计算出轮廓 132 的面积： 12.0\n",
      "OpenCV 函数计算出的面积：-12.00，长度：70.43\n",
      "通过 m00 计算出轮廓 133 的面积： 16.5\n",
      "OpenCV 函数计算出的面积：-16.50，长度：90.33\n",
      "通过 m00 计算出轮廓 134 的面积： 2.0\n",
      "OpenCV 函数计算出的面积：2.00，长度：5.66\n",
      "通过 m00 计算出轮廓 135 的面积： 3.0\n",
      "OpenCV 函数计算出的面积：-3.00，长度：19.31\n",
      "通过 m00 计算出轮廓 136 的面积： 4.5\n",
      "OpenCV 函数计算出的面积：-4.50，长度：47.56\n",
      "通过 m00 计算出轮廓 137 的面积： 12.5\n",
      "OpenCV 函数计算出的面积：-12.50，长度：147.78\n",
      "通过 m00 计算出轮廓 138 的面积： 6.0\n",
      "OpenCV 函数计算出的面积：-6.00，长度：24.97\n",
      "通过 m00 计算出轮廓 139 的面积： 5.0\n",
      "OpenCV 函数计算出的面积：-5.00，长度：55.11\n",
      "通过 m00 计算出轮廓 140 的面积： 18.0\n",
      "OpenCV 函数计算出的面积：-18.00，长度：64.77\n",
      "通过 m00 计算出轮廓 141 的面积： 7.5\n",
      "OpenCV 函数计算出的面积：7.50，长度：11.07\n",
      "通过 m00 计算出轮廓 142 的面积： 14.5\n",
      "OpenCV 函数计算出的面积：-14.50，长度：158.47\n",
      "通过 m00 计算出轮廓 143 的面积： 9.0\n",
      "OpenCV 函数计算出的面积：-9.00，长度：39.46\n",
      "通过 m00 计算出轮廓 144 的面积： 21.5\n",
      "OpenCV 函数计算出的面积：-21.50，长度：82.33\n",
      "通过 m00 计算出轮廓 145 的面积： 12.5\n",
      "OpenCV 函数计算出的面积：12.50，长度：13.90\n",
      "通过 m00 计算出轮廓 146 的面积： 33.0\n",
      "OpenCV 函数计算出的面积：-33.00，长度：69.11\n",
      "通过 m00 计算出轮廓 147 的面积： 25.5\n",
      "OpenCV 函数计算出的面积：25.50，长度：23.56\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./image/76_ContourMoment.jpg\")\n",
    "WIN_NAME = \"Moments\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.blur(gray, (3, 3))\n",
    "\n",
    "\n",
    "def on_moments(_):\n",
    "    t = cv2.getTrackbarPos(\"threshold\", WIN_NAME)\n",
    "\n",
    "    src = cv2.Canny(blur, threshold1=t, threshold2=t*2, apertureSize=3) # 检测边缘\n",
    "    # 寻找轮廓\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        src, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 计算矩\n",
    "    moments = []\n",
    "    for i in range(len(contours)):\n",
    "        moments.append(cv2.moments(contours[i], binaryImage=False))\n",
    "    # 计算中心距\n",
    "    points = np.zeros([len(contours), 2], dtype=\"float32\")\n",
    "    for i in range(len(contours)):\n",
    "        if moments[i]['m00'] == 0:\n",
    "            points[i] = (float('inf'), float('inf'))\n",
    "            continue\n",
    "        points[i] = ((moments[i]['m10'] / moments[i]['m00']), (moments[i]['m01'] / moments[i]['m00']))\n",
    "\n",
    "    # 绘制轮廓\n",
    "    dst = np.zeros(img.shape, img.dtype)\n",
    "    for i in range(len(contours)):\n",
    "        color = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "        # 绘制外层和内层轮廓\n",
    "        cv2.drawContours(dst, contours, i, color, 2, 8, hierarchy, 0, (0, 0))\n",
    "        # 绘制圆\n",
    "        cv2.circle(dst, tuple(points[i].astype(int)), 4, color, -1, 8, 0)\n",
    "\n",
    "    result = np.hstack([img, dst])\n",
    "    cv2.imshow(WIN_NAME, result)\n",
    "    cv2.imshow(\"canny\", src)\n",
    "    \n",
    "    # 通过 m00 计算轮廓面积并且和 OpenCV 函数比较\n",
    "    print(\"输出内容：面积和轮廓长度\")\n",
    "    for i in range(len(contours)):\n",
    "        print(\"通过 m00 计算出轮廓\", i, \"的面积：\", moments[i][\"m00\"])\n",
    "\n",
    "        \"\"\"\n",
    "        contourArea()\n",
    "            用于计算整个轮廓或部分轮廓的面积。\n",
    "            contour     二维向量，轮廓顶点。\n",
    "            oriented    面向区域标识符。\n",
    "                        若为 True，该函数返回一个带符号的面积值，\n",
    "                        其正负取决于轮廓的方向。默认为 False。\n",
    "        arcLength()\n",
    "            用于计算封闭轮廓的周长或曲线的长度\n",
    "            curve       二维点集\n",
    "            closed      用于指示曲线是否封闭的标识符。\n",
    "                        默认为 closed，表示曲线封闭。\n",
    "        \"\"\"\n",
    "        print(\"OpenCV 函数计算出的面积：%.2f，长度：%.2f\" % (cv2.contourArea(contour=contours[i], oriented=True), cv2.arcLength(curve=contours[i], closed=True)))\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"threshold\", WIN_NAME, 100, 255, on_moments)\n",
    "on_moments(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5 - 分水岭算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "程序运行时间为 0.0138116 s\n",
      "the program has exited\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./image/77_watershed.jpg\")\n",
    "WIN_NAME1 = \"original image\"\n",
    "WIN_NAME2 = \"watershed\"\n",
    "src = img.copy()\n",
    "mask = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "mask *= 0\n",
    "prev_pt = (-1, -1)\n",
    "cv2.imshow(WIN_NAME1, src)\n",
    "\n",
    "\n",
    "def on_mouse(event, x, y, flags, _):\n",
    "    global prev_pt\n",
    "    # 当鼠标不在窗口中时\n",
    "    if x < 0 or x >= src.shape[1] or y < 0 or y >= src.shape[0]:\n",
    "        return\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        prev_pt = (-1, -1)\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        prev_pt = (x, y)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "        point = (x, y)\n",
    "        if prev_pt[1] < 0:\n",
    "            prev_pt = point\n",
    "        cv2.line(mask, pt1=prev_pt, pt2=point, color=(255, 255, 255), thickness=5, lineType=8, shift=0)\n",
    "        cv2.line(src, pt1=prev_pt, pt2=point, color=(255, 255, 255), thickness=5, lineType=8, shift=0)\n",
    "        prev_pt = point\n",
    "        cv2.imshow(WIN_NAME1, src)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME1)\n",
    "cv2.setMouseCallback(WIN_NAME1, on_mouse, 0)\n",
    "\n",
    "while True:\n",
    "    key = chr(cv2.waitKey())\n",
    "    if key == 'q':  # 退出程序\n",
    "        print(\"the program has exited\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    if key == 'r':  # 还原图像\n",
    "        print(\"Restore the original image\")\n",
    "        mask *= 0\n",
    "        src = img.copy()\n",
    "        cv2.imshow(WIN_NAME1, src)\n",
    "    if key == ' ':  # 运行\n",
    "        comp_count = 0\n",
    "        # 寻找轮廓\n",
    "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # 轮廓为空时\n",
    "        if contours is None:\n",
    "            continue\n",
    "        # 拷贝掩膜\n",
    "        mask_img = np.zeros(mask.shape, dtype=\"int32\")\n",
    "        mask_img *= 0\n",
    "        # 绘制轮廓\n",
    "        for i in range(len(contours)):\n",
    "            cv2.drawContours(mask_img, contours, i, tuple([comp_count + 1] * 3), -1, 8, hierarchy, cv2.INTER_MAX)\n",
    "            comp_count += 1\n",
    "        # comp_count 为零时\n",
    "        if comp_count == 0:\n",
    "            continue\n",
    "        # 生成随机颜色\n",
    "        color_tab = []\n",
    "        for i in range(comp_count):\n",
    "            color_tab.append((np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)))\n",
    "        # 计算处理时间\n",
    "        time = cv2.getTickCount()\n",
    "        cv2.watershed(img, mask_img)\n",
    "        time = cv2.getTickCount() - time\n",
    "        print(\"程序运行时间为\", time / cv2.getTickFrequency(), \"s\")\n",
    "        # 双层循环，将分水岭图像遍历储存\n",
    "        watershed = np.zeros([mask_img.shape[0], mask_img.shape[1], 3], dtype=\"uint8\")\n",
    "        for i in range(mask_img.shape[0]):\n",
    "            for j in range(mask_img.shape[1]):\n",
    "                index = mask_img[i][j]\n",
    "                if index == -1:\n",
    "                    watershed[i][j] = (255, 255, 255)\n",
    "                elif index <= 0 or index > comp_count:\n",
    "                    watershed[i][j] = (0, 0, 0)\n",
    "                else:\n",
    "                    watershed[i][j] = color_tab[index - 1]\n",
    "        # 混合灰度图和分水岭效果图\n",
    "        watershed = watershed * 0.5 + gray * 0.5\n",
    "        cv2.imshow(WIN_NAME2, watershed.astype(\"uint8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.6 - 图像修补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore the original image\n",
      "the program has exited\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./image/78_inpaint.jpg\")\n",
    "WIN_NAME = \"original image\"\n",
    "src = img.copy()\n",
    "mask = np.zeros([src.shape[0], src.shape[1]], src.dtype)\n",
    "prev_pt = (-1, -1)\n",
    "cv2.imshow(WIN_NAME, src)\n",
    "\n",
    "\n",
    "def on_mouse(event, x, y, flags, _):\n",
    "    global prev_pt\n",
    "    # 当鼠标不在窗口中时\n",
    "    if x < 0 or x >= src.shape[1] or y < 0 or y >= src.shape[0]:\n",
    "        return\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        prev_pt = (-1, -1)\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        prev_pt = (x, y)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "        point = (x, y)\n",
    "        if prev_pt[1] < 0:\n",
    "            prev_pt = point\n",
    "        cv2.line(mask, pt1=prev_pt, pt2=point, color=(255, 255, 255), thickness=5, lineType=8, shift=0)\n",
    "        cv2.line(src, pt1=prev_pt, pt2=point, color=(255, 255, 255), thickness=5, lineType=8, shift=0)\n",
    "        prev_pt = point\n",
    "        cv2.imshow(WIN_NAME, src)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.setMouseCallback(WIN_NAME, on_mouse, 0)\n",
    "\n",
    "while True:\n",
    "    key = chr(cv2.waitKey())\n",
    "    if key == 'q':  # 退出程序\n",
    "        print(\"the program has exited\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    if key == 'r':  # 还原图像\n",
    "        print(\"Restore the original image\")\n",
    "        mask *= 0\n",
    "        src = img.copy()\n",
    "        cv2.imshow(WIN_NAME, src)\n",
    "    if key == ' ':  # 运行\n",
    "        inpaint = cv2.inpaint(src, mask, 3, cv2.INPAINT_TELEA)\n",
    "        cv2.imshow(\"inpaint\", inpaint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第九章 - 直方图与匹配\n",
    "\n",
    "#### 9.2 - 直方图的计算与绘制\n",
    "\n",
    "##### 9.2.3 - 绘制 H-S 直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./image/81_histogram.jpg\")\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hue_bin = 30    # 色调 (hue) 直方图的 bin 数量\n",
    "sat_bin = 32     # 饱和度 (saturation) 直方图的 bin 数量\n",
    "hist_size = [hue_bin, sat_bin]\n",
    "\n",
    "hue_range = [0, 180]    # 定义色调的变化范围\n",
    "sat_range = [0, 256]    # 定义饱和度的变化范围\n",
    "ranges = hue_range + sat_range\n",
    "\n",
    "channels = [0, 1]   # calcHist() 函数中将计算第 0 和第 1 通道的直方图\n",
    "\n",
    "# 计算一个或者多个阵列的直方图\n",
    "hist = cv2.calcHist([hsv],\n",
    "    channels=channels,      # 通道索引\n",
    "    mask=None,              # 不使用掩膜\n",
    "    histSize=hist_size,     # 存放每个维度的直方图尺寸的数组\n",
    "    ranges=ranges,          # 每个维度数值的取值范围数组\n",
    "    accumulate=False)       # 累计标识符。True 表示直方图在配置阶段会被清零。此功能主要是允许从多个阵列中计算单个直方图，或者用于在特定的时间更新直方图\n",
    "\n",
    "# 在数组中找到全局最小值和最大值\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(hist, mask=None)\n",
    "\n",
    "# 双层循环，绘制直方图\n",
    "scale = 20  # 控制 H-V 直方图的显示大小\n",
    "hist_img = np.zeros([sat_bin*scale, hue_bin*scale, 3], dtype=\"uint8\")\n",
    "for hue in range(hue_bin):\n",
    "    for sat in range(sat_bin):\n",
    "        bin_val = hist[hue][sat]  # 直方图 bin 的值\n",
    "        intensity = round(bin_val * 255 / max_val)    # 强度\n",
    "        cv2.rectangle(hist_img,\n",
    "            pt1=(hue*scale, sat*scale),\n",
    "            pt2=((hue+1)*scale-1, (sat+1)*scale-1),\n",
    "            color=tuple([intensity]*3),\n",
    "            thickness=cv2.FILLED)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Result\", hist_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.2.4 - 计算并绘制图像一维直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./image/81_histogram.jpg\")\n",
    "hist = cv2.calcHist([img], channels=[0], mask=None, histSize=[256], ranges=[0, 255], accumulate=False)\n",
    "scale = 2   # 控制一维直方图的显示宽度，或者说 bin 的间距\n",
    "size = 256\n",
    "dst = np.zeros([size, size*scale], dtype=\"uint8\")\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(hist, mask=None)\n",
    "hpt = 0.9 * size\n",
    "\n",
    "for i in range(256):\n",
    "    bin_val = hist[i]\n",
    "    real_val = int(np.round(bin_val * hpt / max_val))   # rectangle() 要求坐标的数据类型为 int，而 np.round 输出的是 float\n",
    "    cv2.rectangle(dst, pt1=(i*scale, size-1), pt2=((i+1)*scale-1, size-real_val), color=(255, 255, 255))\n",
    "\n",
    "cv2.imshow(\"Result\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 - 直方图对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation 方法的匹配结果为：\n",
      "【基准图 - 基准图】\t 1.000\n",
      "【基准图 - 测试图 1】\t 0.267\n",
      "【基准图 - 测试图 2】\t 0.130\n",
      "【基准图 - 半身图】\t 0.909\n",
      "\n",
      "Chi-Square 方法的匹配结果为：\n",
      "【基准图 - 基准图】\t 0.000\n",
      "【基准图 - 测试图 1】\t 4940.944\n",
      "【基准图 - 测试图 2】\t 3960.965\n",
      "【基准图 - 半身图】\t 21.229\n",
      "\n",
      "直方图相交 方法的匹配结果为：\n",
      "【基准图 - 基准图】\t 58.699\n",
      "【基准图 - 测试图 1】\t 7.323\n",
      "【基准图 - 测试图 2】\t 4.538\n",
      "【基准图 - 半身图】\t 33.234\n",
      "\n",
      "Bhattacharyya 距离 方法的匹配结果为：\n",
      "【基准图 - 基准图】\t 0.000\n",
      "【基准图 - 测试图 1】\t 0.603\n",
      "【基准图 - 测试图 2】\t 0.663\n",
      "【基准图 - 半身图】\t 0.359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "compareHist() 对比两个直方图的相似度\n",
    "method:\n",
    "- HISTCMP_CORREL            相关, Correlation\n",
    "- HISTCMP_CHISQR            卡方, Chi-Square\n",
    "- HISTCMP_INTERSECT         直方图相交, Intersection\n",
    "- HISTCMP_BHATTACHARYYA     Bhattacharyya 距离\n",
    "\"\"\"\n",
    "\n",
    "img1 = cv2.imread(\"./image/82_compareHist_1.jpg\")\n",
    "img2 = cv2.imread(\"./image/82_compareHist_2.jpg\")\n",
    "img3 = cv2.imread(\"./image/82_compareHist_3.jpg\")\n",
    "img_show = np.hstack([img1, img2, img3])\n",
    "cv2.imshow(\"image\", img_show)\n",
    "\n",
    "hsv1 = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)    # 基准图\n",
    "hsv2 = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)    # 测试图\n",
    "hsv3 = cv2.cvtColor(img3, cv2.COLOR_BGR2HSV)\n",
    "# 创建包含基准图像下半部分的半身图像（HSV 格式）\n",
    "hsv_half_down = hsv1[round(hsv1.shape[0]/2):hsv1.shape[0], 0:hsv1.shape[1]]\n",
    "\n",
    "hue_bin = 50\n",
    "sat_bin = 60\n",
    "hist_size = [hue_bin, sat_bin]\n",
    "hue_range = [0, 256]\n",
    "sat_range = [0, 180]\n",
    "ranges = hue_range + sat_range\n",
    "channels = [0, 1]\n",
    "\n",
    "\n",
    "def my_calcHist(img):\n",
    "    hist = cv2.calcHist([img], channels=channels, mask=None, histSize=hist_size, ranges=ranges, accumulate=False)\n",
    "    cv2.normalize(src=hist, dst=hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=-1, mask=None)\n",
    "    \n",
    "    return hist\n",
    "\n",
    "\n",
    "hist1 = my_calcHist(hsv1)\n",
    "hist2 = my_calcHist(hsv2)\n",
    "hist3 = my_calcHist(hsv3)\n",
    "hist_half_down = my_calcHist(hsv_half_down)\n",
    "\n",
    "# 按顺序使用 4 种对比标准来对比直方图\n",
    "methods_dict = {'Correlation': cv2.HISTCMP_CORREL,\n",
    "                'Chi-Square': cv2.HISTCMP_CHISQR,\n",
    "                '直方图相交': cv2.HISTCMP_INTERSECT,\n",
    "                'Bhattacharyya 距离': cv2.HISTCMP_BHATTACHARYYA}\n",
    "methods_idx = list(methods_dict.values())\n",
    "methods_name = list(methods_dict.keys())\n",
    "for i in range(len(methods_dict)):\n",
    "    ch1 = cv2.compareHist(H1=hist1, H2=hist1, method=methods_idx[i])\n",
    "    ch2 = cv2.compareHist(H1=hist1, H2=hist2, method=methods_idx[i])\n",
    "    ch3 = cv2.compareHist(H1=hist1, H2=hist3, method=methods_idx[i])\n",
    "    ch_half_down = cv2.compareHist(H1=hist1, H2=hist_half_down, method=methods_idx[i])\n",
    "    \n",
    "    print(methods_name[i], \"方法的匹配结果为：\")\n",
    "    print(\"【基准图 - 基准图】\\t %.3f\" % ch1)\n",
    "    print(\"【基准图 - 测试图 1】\\t %.3f\" % ch2)\n",
    "    print(\"【基准图 - 测试图 2】\\t %.3f\" % ch3)\n",
    "    print(\"【基准图 - 半身图】\\t %.3f\" % ch_half_down)\n",
    "    print()\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4 - 反向投影\n",
    "\n",
    "首先计算某一特征的直方图模型，然后使用模型去寻找图像中存在的该特征。\n",
    "\n",
    "反向投影中储存的数值代表了测试图像中该像素属于特征区域的概率。\n",
    "\n",
    "反向投影的过程是【原图像 -> 直方图 -> 反向投影】，算法步骤有点类似于直方图均衡化，只不过，直方图均衡化是将图像结果中的每个像素的值由一个地方搬到另一个新地方，而 back project 是直接取直方图中的值。以灰度图为例，某种灰度值在整幅图像中所占面积越大，其在直方图中的值越大，back project 时，其对应的像素的新值越大（越亮），反过来，某灰度值所占面积越小，其新值就越小。\n",
    "\n",
    "![img](image_host/2022-03-10-11-03-03.png)\n",
    "\n",
    "---\n",
    "\n",
    "版权声明：上述部分表达转自 CSDN 博主「viewcode」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
    "\n",
    "原文链接：https://blog.csdn.net/viewcode/article/details/8209067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./image/83_calcBackProject.jpg\")\n",
    "WIN_NAME = \"back project\"\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\"\"\"\n",
    "# 通道复制 - 由输入参数复制某通道到输出参数特定的通道中\n",
    "hue_img = np.zeros(hsv.shape, hsv.dtype)    # 所有矩阵必须初始化，且大小和深度与 src 相同\n",
    "ch = [0, 0]     # 对指定的通道进行复制的数组索引\n",
    "cv2.mixChannels([hsv], dst=[hue_img], fromTo=ch)    # 只使用 hue 通道值\n",
    "\"\"\"\n",
    "# 与上述代码等价，split() 和 merge() 是 mixChannels() 的一部分\n",
    "hue_img, _, _ = cv2.split(hsv)\n",
    "\n",
    "\n",
    "def on_bin_change(_):\n",
    "    bin = cv2.getTrackbarPos(\"bin\", WIN_NAME)   # 直方图组距\n",
    "    scale = cv2.getTrackbarPos(\"scale\", WIN_NAME)\n",
    "    \n",
    "    hist_size = [max(bin, 2)]\n",
    "    ranges = [0, 180]\n",
    "    \n",
    "    # 计算直方图并归一化\n",
    "    hist = cv2.calcHist([hue_img],\n",
    "        channels=[0],\n",
    "        mask=None,\n",
    "        histSize=hist_size,\n",
    "        ranges=ranges,\n",
    "        accumulate=False)\n",
    "    cv2.normalize(src=hist, dst=hist, alpha=0, beta=255,\n",
    "        norm_type=cv2.NORM_MINMAX, \n",
    "        dtype=-1, mask=None)\n",
    "    \n",
    "    # 计算反向投影\n",
    "    back_project = cv2.calcBackProject([hue_img],\n",
    "        channels=[0],   # 需要统计的通道索引\n",
    "        hist=hist,      # 输入的直方图\n",
    "        ranges=ranges,  # 每一维数组的取值范围\n",
    "        scale=scale)    # 输出的方向投影可选的缩放因子，默认为 1\n",
    "    \n",
    "    cv2.imshow(\"original image\", img)\n",
    "    cv2.imshow(WIN_NAME, back_project)\n",
    "    \n",
    "    # 绘制直方图\n",
    "    w, h = 400, 400\n",
    "    bin_w = round(w / max(bin, 2))\n",
    "    hist_img = np.zeros([w, h, 3], dtype=\"uint8\")\n",
    "    for i in range(bin):\n",
    "        cv2.rectangle(hist_img,\n",
    "            pt1=(i*bin_w, h),\n",
    "            pt2=((i+1)*bin_w, h-int(np.round(hist[i]*h/255))),\n",
    "            color=(100, 123, 255),\n",
    "            thickness=-1)\n",
    "    \n",
    "    cv2.imshow(\"hist\", hist_img)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"bin\", WIN_NAME, 30, 180, on_bin_change)\n",
    "cv2.createTrackbar(\"scale\", WIN_NAME, 1, 10, on_bin_change)\n",
    "on_bin_change(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.5 - 模板匹配\n",
    "\n",
    "模板匹配不是基于直方图，而是通过在输入图像上滑动图像块，对输入图像进行匹配的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_base = cv2.imread(\"./image/84_matchTemplate_1.jpg\")\n",
    "template = cv2.imread(\"./image/84_matchTemplate_2.jpg\")\n",
    "WIN_NAME = \"match\"\n",
    "methods = [cv2.TM_SQDIFF,   # 平方差匹配法\n",
    "    cv2.TM_SQDIFF_NORMED,   # 归一化平方差匹配法\n",
    "    cv2.TM_CCORR,           # 相关匹配法\n",
    "    cv2.TM_CCORR_NORMED,    # 归一化相关匹配法\n",
    "    cv2.TM_CCOEFF,          # 系数匹配法\n",
    "    cv2.TM_CCOEFF_NORMED]   # 化相关系数匹配法\n",
    "\n",
    "def on_match(_):\n",
    "    idx = cv2.getTrackbarPos(\"method index\", WIN_NAME)\n",
    "    \n",
    "    src = img_base.copy()\n",
    "    # 进行匹配和标准化\n",
    "    res = cv2.matchTemplate(src, templ=template, method=methods[idx], mask=None)\n",
    "    cv2.normalize(res, res, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=-1, mask=None)\n",
    "    \n",
    "    # 通过 minMaxLoc() 定位最匹配的位置\n",
    "    _, _, min_loc, max_loc = cv2.minMaxLoc(res, mask=None)\n",
    "    \n",
    "    # 对于 SQDIFF 和 SQDIFF_NORMED，越小的值有着越高的匹配度，而其余的方法与此相反\n",
    "    if methods[idx] == cv2.TM_SQDIFF or methods[idx] == cv2.TM_SQDIFF_NORMED:\n",
    "        match_loc = min_loc\n",
    "    else:\n",
    "        match_loc = max_loc\n",
    "    \n",
    "    # 绘制出矩形，并显示结果\n",
    "    cv2.rectangle(src, pt1=match_loc,\n",
    "        pt2=(match_loc[0]+template.shape[1], match_loc[1]+template.shape[0]),\n",
    "        color=(0, 0, 255),\n",
    "        thickness=2,\n",
    "        lineType=8)\n",
    "    cv2.rectangle(res, pt1=match_loc,\n",
    "        pt2=(match_loc[0]+template.shape[1], match_loc[1]+template.shape[0]),\n",
    "        color=(0, 0, 255),\n",
    "        thickness=2,\n",
    "        lineType=8)\n",
    "    \n",
    "    cv2.imshow(\"original image\", src)\n",
    "    cv2.imshow(WIN_NAME, res)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"method index\", WIN_NAME, 0, len(methods)-1, on_match)\n",
    "on_match(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四部分 - 深入 feature2d 组件\n",
    "\n",
    "### 第十章 - 角点检测\n",
    "\n",
    "关于角点的描述：\n",
    "\n",
    "- 一阶导数（即灰度的梯度）的局部最大值所对应的像素点\n",
    "- 两条及两条以上边缘的交点\n",
    "- 图像中梯度值和梯度方向的变化速率都很高的点\n",
    "- 角点处的一阶导数最大，二阶导数为零，它指示了物体边缘变化不连续的方向。\n",
    "\n",
    "角点检测也称为特征点检测。实际应用中，大多数所谓的角点检测方法检测的是拥有特定特征的图像点，而不仅仅是“角点”。\n",
    "\n",
    "焦点检测的方法归纳：\n",
    "\n",
    "- 基于灰度图像\n",
    "  - 基于梯度\n",
    "  - 基于模板\n",
    "    - 主要考虑像素邻域点的灰度变化，即图像亮度的变化，将与邻域点亮度对比足够大的点定义为角点。\n",
    "    - Kitchen-Rosenfeld 角点检测算法\n",
    "    - Harris 角点检测算法\n",
    "    - KLT 角点检测算法\n",
    "    - SUSAN 角点检测算法\n",
    "  - 基于模板梯度组合\n",
    "- 基于二值图像\n",
    "- 基于轮廓曲线\n",
    "\n",
    "#### 10.1 - Harris 角点检测\n",
    "\n",
    "稳定性高，尤其对 L 型角点检测精度高。\n",
    "\n",
    "但由于采用了高斯滤波，运算速度相对较慢，角点信息有丢失和位置偏移的现象，而且角点提取有聚簇现象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(\"./image/85_cornerHarris.jpg\", 0)\n",
    "img = cv2.imread(\"./image/86_cornerHarris.jpg\")\n",
    "WIN_NAME = \"Harris Corner Detection\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def on_corner_harris(_):\n",
    "    t = cv2.getTrackbarPos(\"threshold\", WIN_NAME)\n",
    "    \n",
    "    dst = cv2.cornerHarris(gray,\n",
    "        blockSize=2,    # 表示邻域的大小\n",
    "        ksize=3,        # 表示 Sobel() 算子的孔径大小\n",
    "        k=0.04,         # Harris 参数\n",
    "        borderType=cv2.BORDER_DEFAULT)  # 图像像素的边界模式\n",
    "    _, harris = cv2.threshold(dst, thresh=1e-4, maxval=255, type=cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 归一化与转化\n",
    "    norm = np.zeros(dst.shape, dtype=\"float32\")\n",
    "    cv2.normalize(dst, norm, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32FC1, mask=None)\n",
    "    scale = cv2.convertScaleAbs(norm)   # 将归一化后的图像线性变换成 uint8 数据类型\n",
    "    \n",
    "    # 绘制检测到的且符合阈值条件的角点\n",
    "    src = img.copy()\n",
    "    for i in range(norm.shape[0]):\n",
    "        for j in range(norm.shape[1]):\n",
    "            if norm[i][j] > t + 80:\n",
    "                cv2.circle(src, center=(j, i), radius=5, color=(10, 10, 255), thickness=2, lineType=8)\n",
    "                cv2.circle(scale, center=(j, i), radius=5, color=(0, 10, 255), thickness=2, lineType=8)\n",
    "    \n",
    "    cv2.imshow(\"original image\", src)\n",
    "    cv2.imshow(WIN_NAME, scale)\n",
    "    cv2.imshow(\"Harris\", harris)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"threshold\", WIN_NAME, 30, 175, on_corner_harris)\n",
    "on_corner_harris(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 - Shi-Tomasi 角点检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./image/87_goodFeaturesToTrack.jpg\")\n",
    "WIN_NAME = \"Shi-Tomasi Corner Detection\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def on_GFT(_):\n",
    "    max_corner_num = cv2.getTrackbarPos(\"max corner number\", WIN_NAME)\n",
    "    if max_corner_num <= 1:\n",
    "        max_corner_num = 1\n",
    "    flag = False\n",
    "    if cv2.getTrackbarPos(\"use Harris Detector\", WIN_NAME) == 1:\n",
    "        flag = True\n",
    "    block_size = cv2.getTrackbarPos(\"block size\", WIN_NAME) + 1\n",
    "    \n",
    "    corners = cv2.goodFeaturesToTrack(gray,\n",
    "        maxCorners=max_corner_num,  # 角点的最大数量\n",
    "        qualityLevel=0.01,          # 角点检测可接受的最小特征值\n",
    "        minDistance=10,             # 角点之间的最小距离\n",
    "        mask=None,                  # 感兴趣区域\n",
    "        blockSize=block_size,       # 计算导数自相关矩阵时指定的邻域范围，默认为 3\n",
    "        useHarrisDetector=flag,     # 不使用 Harris 角点检测\n",
    "        k=0.04)                     # 用于设置 Hessian 自相关矩阵行列式的相对权重的权重系数\n",
    "    \n",
    "    src = img.copy()\n",
    "    for i in range(len(corners)):\n",
    "        color = (np.random.randint(255), np.random.randint(255), np.random.randint(255))\n",
    "        cv2.circle(src, center=(int(corners[i][0][0]), int(corners[i][0][1])),\n",
    "            radius=4, color=color, thickness=-1, lineType=8)\n",
    "    \n",
    "    cv2.imshow(WIN_NAME, src)\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"max corner number\", WIN_NAME, 33, 500, on_GFT)\n",
    "cv2.createTrackbar(\"use Harris Detector\", WIN_NAME, 0, 1, on_GFT)\n",
    "cv2.createTrackbar(\"block size\", WIN_NAME, 2, 20, on_GFT)\n",
    "on_GFT(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3 - 亚像素级角点检测\n",
    "\n",
    "若我们进行图像处理的目的不是提取用于识别的特征点而是进行几何测量，这通常需要更高的精度（实数坐标值）\n",
    "\n",
    "亚像素级角点检测的位置在摄像机标定、跟踪并重建摄像机的轨迹，或者重建被跟踪目标的三维结构时，是一个基本的测量值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 1, 2)\n",
      "精确角点坐标【0】\t(360.6143,594.07764)\n",
      "精确角点坐标【1】\t(103.15959,583.7792)\n",
      "精确角点坐标【2】\t(448.3073,591.67004)\n",
      "精确角点坐标【3】\t(230.0,576.0)\n",
      "精确角点坐标【4】\t(420.0,631.0)\n",
      "精确角点坐标【5】\t(183.23918,581.2203)\n",
      "精确角点坐标【6】\t(144.0,339.0)\n",
      "精确角点坐标【7】\t(144.0,216.0)\n",
      "精确角点坐标【8】\t(144.0,172.0)\n",
      "精确角点坐标【9】\t(304.0,309.0)\n",
      "精确角点坐标【10】\t(154.69167,367.2343)\n",
      "精确角点坐标【11】\t(304.0,288.0)\n",
      "精确角点坐标【12】\t(144.0,127.0)\n",
      "精确角点坐标【13】\t(321.0,483.0)\n",
      "精确角点坐标【14】\t(331.0,514.0)\n",
      "精确角点坐标【15】\t(145.0,231.0)\n",
      "精确角点坐标【16】\t(144.0,138.0)\n",
      "精确角点坐标【17】\t(62.547638,534.58203)\n",
      "精确角点坐标【18】\t(144.0,205.0)\n",
      "精确角点坐标【19】\t(327.0,501.0)\n",
      "精确角点坐标【20】\t(143.28537,376.61914)\n",
      "精确角点坐标【21】\t(162.77371,585.33075)\n",
      "精确角点坐标【22】\t(112.84287,590.2583)\n",
      "精确角点坐标【23】\t(299.0,348.0)\n",
      "精确角点坐标【24】\t(254.15288,536.3996)\n",
      "精确角点坐标【25】\t(310.0,449.0)\n",
      "精确角点坐标【26】\t(314.0,462.0)\n",
      "精确角点坐标【27】\t(296.0,237.0)\n",
      "精确角点坐标【28】\t(145.0,114.0)\n",
      "精确角点坐标【29】\t(299.0,255.0)\n",
      "精确角点坐标【30】\t(143.0,257.0)\n",
      "精确角点坐标【31】\t(302.0,274.0)\n",
      "精确角点坐标【32】\t(311.76083,257.8652)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./image/88_cornerSubPix.jpg\")\n",
    "WIN_NAME = \"Sub-pixel Corner Detection\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def on_CSP(_):\n",
    "    max_corner_num = cv2.getTrackbarPos(\"max corner number\", WIN_NAME)\n",
    "    if max_corner_num <= 1:\n",
    "        max_corner_num = 1\n",
    "    flag = False\n",
    "    if cv2.getTrackbarPos(\"use Harris Detector\", WIN_NAME) == 1:\n",
    "        flag = True\n",
    "    block_size = cv2.getTrackbarPos(\"block size\", WIN_NAME) + 1\n",
    "    \n",
    "    corners = cv2.goodFeaturesToTrack(gray,\n",
    "        maxCorners=max_corner_num,  # 角点的最大数量\n",
    "        qualityLevel=0.01,          # 角点检测可接受的最小特征值\n",
    "        minDistance=10,             # 角点之间的最小距离\n",
    "        mask=None,                  # 感兴趣区域\n",
    "        blockSize=block_size,       # 计算导数自相关矩阵时指定的邻域范围，默认为 3\n",
    "        useHarrisDetector=flag,     # 不使用 Harris 角点检测\n",
    "        k=0.04)                     # 用于设置 Hessian 自相关矩阵行列式的相对权重的权重系数\n",
    "    \n",
    "    src = img.copy()\n",
    "    for i in range(len(corners)):\n",
    "        color = (np.random.randint(255), np.random.randint(255), np.random.randint(255))\n",
    "        cv2.circle(src, center=(int(corners[i][0][0]), int(corners[i][0][1])),\n",
    "            radius=4, color=color, thickness=-1, lineType=8)\n",
    "    \n",
    "    cv2.imshow(WIN_NAME, src)\n",
    "    \n",
    "    # 计算出亚像素角点位置\n",
    "    cv2.cornerSubPix(gray,\n",
    "        corners=corners,\n",
    "        winSize=(5, 5),\n",
    "        zeroZone=(-1, -1),\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 40, 0.001))\n",
    "    print(corners.shape)\n",
    "    \n",
    "    # 输出角点信息\n",
    "    for i in range(len(corners)):\n",
    "        print(\"精确角点坐标【\" + str(i) + \"】\\t(\" + str(corners[i][0][0]) + \",\" + str(corners[i][0][1]) + \")\")\n",
    "\n",
    "\n",
    "cv2.namedWindow(WIN_NAME)\n",
    "cv2.createTrackbar(\"max corner number\", WIN_NAME, 33, 500, on_CSP)\n",
    "cv2.createTrackbar(\"use Harris Detector\", WIN_NAME, 0, 1, on_CSP)\n",
    "cv2.createTrackbar(\"block size\", WIN_NAME, 2, 20, on_CSP)\n",
    "on_CSP(0)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第十一章 - 特征检测与匹配\n",
    "\n",
    "#### 11.1 - SURF 特征点检测\n",
    "\n",
    "Speeded Up Robust Features，加速版的具有鲁棒性的特征算法\n",
    "\n",
    "由 Bay 在 2006 年首次提出，是尺度不变特征变换算法（SIFT）的加速版，在多幅图片下具有更好的稳定性，最大的区别在于采用了 harr 特征以及积分图像的概念。\n",
    "\n",
    "---\n",
    "\n",
    "学海无涯，未完待续 ..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c85909c066b39d857071483c78a937d00aa7546f1f52ba3c0924986ff839b8c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
